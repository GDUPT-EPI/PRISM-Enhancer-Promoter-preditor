目标：在无标签下游环境中，不重新训练主干，仅基于已训练的旁路解耦权重，利用 OOD 细胞系的共性 G 与特性 F 的分布，方向性地偏置迁移已有知识，近似得到 EP 交互 I，并提升最终 EP 判定的鲁棒性与准确性。

---

### 一、 EP 互作的概率分解模型 (The Probability Decomposition)

我们将 $P(y=1 | x_E, x_P, c)$ 分解为两个相互独立的因子：

$$ P(y=1) \approx P(\text{Compatible} | x_E, x_P) \times P(\text{Active} | x_E, x_P, M_{cell}) $$

1.  **$P(\text{Compatible})$ [由 Backbone 负责]**：
    *   这是序列层面的硬约束（Hard Constraint）。
    *   例如：Enhancer 和 Promoter 是否拥有匹配的转录因子结合位点？DNA 环化（Looping）的结构基础是否存在？
    *   **数学性质**：这是 **跨细胞系不变 (Invariant)** 的。你的 Backbone 已经在预训练中学会了这一点，这是它能达到 60% 的基础。

2.  **$P(\text{Active})$ [由 Bypass + FiLM 负责]**：
    *   这是环境层面的软约束（Soft Constraint）。
    *   例如：在这个细胞系中，这些位点是否处于开放染色质区域（Open Chromatin）？相关的 TF 是否表达？
    *   **数学性质**：这是 **环境敏感 (Context-Sensitive)** 的。这正是 60% -> 75% 的增量来源。

结论：下游适应必须冻结 Backbone，仅在隐变量层面调整环境参数，不可用 0/1 标签直接回传至 Backbone。

---

### 二、 为什么直接使用 0/1 更新不可行？ (The Failure of Binary Supervision)

假设下游任务是一个全新的细胞系 $C_{new}$。
如果是一个正样本 $(x_E, x_P, y=1)$：
*   模型需要 $P(\text{Compatible}) \uparrow$ 且 $P(\text{Active}) \uparrow$。
*   这没问题，梯度会强化两者。

**但如果是一个负样本 $(x_E, x_P, y=0)$：**
*   这才是问题的关键。负样本有两种情况：
    *   **Case A (结构不匹配)**：序列根本不搭。此时 $P(\text{Compatible}) \approx 0$。
    *   **Case B (环境抑制)**：序列完美匹配，但染色质关闭。此时 $P(\text{Compatible}) \approx 1$，但 $P(\text{Active}) \approx 0$。
*   在 Hard Negative Mining 中，**Case B 占绝大多数**。
*   如果你直接用 $y=0$ 回传梯度更新 Backbone，你会强行压低 $P(\text{Compatible})$。
*   **数学后果**：模型学会了“在这个细胞系里，这个 Motif 组合是错的”。但这违反了生物化学原理（Motif 结合是物理属性）。当你换一个细胞系（该区域开放）时，模型就会误判。

**结论**：在下游适应时，**必须锁定 $P(\text{Compatible})$（即冻结 Backbone）**，仅允许梯度去寻找使得 $P(\text{Active}) \approx 0$ 的环境参数 $M_{cell}$。

---

### 三、 适应性训练的数学目标：能量最小化 (Energy Minimization)

我们适应的是环境隐变量 $M_{cell}$，以能量最小化视角进行变分推断。

定义系统的 **自由能 (Free Energy)** $F(x, M)$。
对于下游的一批无标签数据 $X_{batch}$，我们假设它们服从某种潜在的生物学规律。我们寻找最优的 $M^*$ 来解释这些观测数据。

#### 1. 互作一致性势能 (Interaction Consistency Potential)
EP 互作不是随机的，它具有稀疏性和聚集性。
Backbone 输出的特征向量 $h_E, h_P$ 包含序列信息。
$$ \mathcal{L}_{align} = - \sum_{i} \text{Sim}(h_{E_i}, h_{P_i}) \cdot \mathcal{G}(M) $$
这不够。我们需要利用你 `decouple.py` 中的 $I$ (Interaction) 分量。
在 Bypass 中，我们有一个 $z_I$。
对于同一个 batch 的数据，如果 Backbone 认为它们“很像互作”（$P(\text{Compatible})$ 高），而当前的 $M$ 导致 $P(\text{Active})$ 很低，这就产生了 **认知失调 (Cognitive Dissonance)** 或 **高能量状态**。

适应目标：
$$ M^* = \arg\min_M \left( \mathcal{H}(\hat{y}(x, M)) + \lambda \cdot D_{KL}(M || \mathcal{M}_{GCN}) \right) $$

*   **$\mathcal{H}(\hat{y})$ (熵最小化)**：
    *   如果 $M$ 是错误的（例如把 K562 当成了 GM12878），FiLM 会进行错误的调制，导致 Backbone 的特征变得混乱，最终预测值 $\hat{y}$ 会徘徊在 0.5 左右（不确定）。
    *   如果 $M$ 是正确的，它会精准地通过 FiLM 抑制那些“本细胞系不开放”的噪音，放大真正的信号，使得 $\hat{y}$ 趋向 0 或 1。
    *   **这就是 60% -> 75% 的数学原理：通过正确的 $M$ 过滤掉 Case B 类的假阳性，大幅提升 Precision，从而提升 AUC/AUPR。**

*   **流形约束**：$M$ 必须位于 GraphContext 学到的细胞系流形 $\mathcal{M}_{GCN}$ 上。

---

### 四、 针对 EP 互作的鲁棒性最大化设计

方向性偏置迁移的核心是构造一个来自 $G/F$ 的门控系数 $\alpha(x,c) \in [0,1]$，作为环境许可度，对 Backbone 的序列互作势能进行调制，并从 $z_I$ 导出近似 EP 交互强度。

1) 环境门控（基于 F 原型的 RBF 对齐）：
设 GraphContext 给出目标细胞原型 $\mu_c$，则对样本 $x$ 的特性向量 $z_F(x)$ 定义
$$ \alpha_F(x,c) = \exp\left(-\frac{\|z_F(x) - \mu_c\|^2}{\tau_F}\right) $$
其中 $\tau_F>0$ 为温度超参数。$\alpha_F$ 越大，表示样本与当前细胞环境越一致，越应当允许环境调制。

2) 共性校准（可选）：
以全局共性均值 $\bar{z}_G$ 进行余弦相似度校准
$$ s_G(x) = \max\{\cos(z_G(x), \bar{z}_G), 0\} $$
令 $\alpha(x,c) = \alpha_F(x,c) \cdot \big(\beta_0 + \beta_1 s_G(x)\big)$，$\beta_0,\beta_1 \ge 0$。

3) 交互近似（来源于 $z_I$ 的规范化强度）：
定义
$$ I_{\text{approx}}(x) = \sigma\Big(\kappa\cdot \frac{\|z_I(x)\| - m_I}{s_I + \varepsilon}\Big) $$
其中 $m_I,s_I$ 分别为当前批次 $\|z_I\|$ 的均值与标准差，$\kappa>0$ 控制斜率，$\sigma$ 为 Sigmoid。

4) 融合算子（FiLM 的方向性门控与交互偏置）：
记 Backbone 特征为 $H(x)$，旁路产生的 FiLM 参数为 $\gamma(M),\beta(M)$，则
$$ \tilde{H}(x,c) = (1-\alpha(x,c))\cdot H(x) + \alpha(x,c)\cdot (\gamma\odot H(x) + \beta) $$
最终判定的对数几率近似为
$$ \ell(x,c) = f_{\text{KAN}}\big(\tilde{H}(x,c)\big) + \lambda_I\cdot \big(I_{\text{approx}}(x) - \tfrac{1}{2}\big) $$
其中 $f_{\text{KAN}}$ 为 FourierKAN 头，$\lambda_I$ 为小权重，将 $z_I$ 的交互强度作为方向性偏置注入到决策中。输出概率为 $\hat{y}(x,c) = \sigma(\ell(x,c))$。

该方案仅依赖已训练旁路的 $z_G,z_F,z_I,\mu_c$ 与 FiLM 映射，不需要重新训练主干；$\alpha$ 与 $I_{\text{approx}}$ 完全由统计与几何关系给出，具备明确的方向性：当样本的 $z_F$ 明显偏离目标细胞原型时，降低环境调制权重，避免将环境许可错误地施加到不匹配的序列；当 $\|z_I\|$ 较大时，通过轻量的偏置提升对高兼容样本的置信度，从而在难测试集中显著抑制假阳性并提升 AUPR/AUC。

原型混合与对数几率单调校准：

5) 原型混合门控（缓解过抑制）：
GraphContext 提供每个细胞的多个原型 $\{p_{c,k}\}$。定义当前细胞的原型权重与其他细胞的权重：
$$ w_{c,k}(x) = \frac{\exp\big(-\|z_F(x) - p_{c,k}\|^2/\tau_F\big)}{\sum_{j}\exp\big(-\|z_F(x) - p_{c,j}\|^2/\tau_F\big)} $$
$$ w_{\text{other}}(x) = \frac{\sum_{c'\ne c}\sum_k \exp\big(-\|z_F(x) - p_{c',k}\|^2/\tau_F\big)}{\sum_{c''}\sum_k \exp\big(-\|z_F(x) - p_{c'',k}\|^2/\tau_F\big)} $$
令 $\bar{w}_c(x)$ 与 $\bar{w}_{other}(x)$ 为样本对当前细胞原型与其他细胞原型的平均权重，则
$$ \alpha(x,c) \leftarrow \text{clip}\Big(\alpha(x,c) + \beta_2\cdot(\bar{w}_c(x) - \bar{w}_{other}(x)),\,0,\,1\Big) $$
该修正避免在 OOD 环境下对可能属于其他域的样本过度施加当前域的环境许可，从而保护召回并稳定 AUPR。

6) 对数几率单调校准（保护 PR/AUPR）：
避免在概率空间线性混合，采用对数几率的加性偏置，保持变换的单调性：
$$ \text{logit}_{\text{cal}}(x,c) = \text{logit}_{\text{dir}}(x,c) + \theta_I\cdot\big(I_{\text{approx}}(x) - \tfrac{1}{2}\big) + \theta_C\cdot\big(\bar{w}_c(x) - \bar{w}_{other}(x)\big) $$
$$ \hat{y}_{\text{cal}}(x,c) = \sigma\big(\text{logit}_{\text{cal}}(x,c)\big) $$
该方式在维持排序单调的同时引入方向性偏置，通常能在不显著牺牲召回的情况下提升 AUC 并稳定 AUPR。

7) 评估期保守选择（防止性能退化）：
在评估阶段同时计算基线 $\hat{y}_{\text{base}}$ 与方向性校准 $\hat{y}_{\text{cal}}$，按细胞系选择能给出更高 AUPR 的方案用于汇总与绘图，避免在未知域中因错误校准导致的指标下降。

8) 高价值策略：混合门控与置信回退

为提升在 OOD 细胞系中的 AUPR，同时保持 AUC 的增益，需要引入两个高价值的数学策略：

8.1 混合门控（Mixture-of-Gates）
将 $\alpha$ 分解为两部分：$\alpha_\text{near}$ 与 $\alpha_\text{far}$，分别反映样本到当前细胞原型的近邻度与到其他细胞原型的近邻度：
$$ \alpha_\text{near}(x,c) = \exp\big(-\|z_F(x)-\mu_c\|^2/\tau_F\big) $$
$$ \alpha_\text{far}(x,c) = \frac{\sum_{c'\ne c}\sum_k \exp\big(-\|z_F(x) - p_{c',k}\|^2/\tau_F\big)}{\sum_{c''}\sum_k \exp\big(-\|z_F(x) - p_{c'',k}\|^2/\tau_F\big)} $$
令
$$ \alpha(x,c) = \text{clip}\Big( \alpha_\text{near}(x,c)\cdot(\beta_0 + \beta_1\,s_G(x)) + \beta_2\,(\alpha_\text{near}(x,c) - \alpha_\text{far}(x,c)),\,0,\,1 \Big) $$
该混合门控在“近当前细胞原型且远离其他细胞原型”时放大环境调制；当样本更像其他细胞原型时则抑制当前域的调制，从而在 OOD 上保护 PR 面积。

8.2 置信回退（Confidence Backoff）
当方向性校准导致的概率置信度过低或排序不稳定时，回退至基线预测的加权融合：
记 $p_{\text{dir}} = \sigma(\text{logit}_{\text{dir}})$，$p_{\text{base}} = \sigma(\text{logit}_{\text{base}})$，定义置信指示：
$$ u(x) = \mathbb{1}\{\alpha(x,c) < \tau_\alpha\} \vee \mathbb{1}\{I_{\text{approx}}(x) < \tau_I\} $$
最终融合：
$$ p_{\text{mix}}(x) = (1-u)\,p_{\text{cal}}(x) + u\,p_{\text{base}}(x) $$
其中 $\tau_\alpha, \tau_I$ 为保守阈值（如 0.2, 0.4）。这保证在方向性信号不可靠时，自动回退到基线，避免 PR 的严重下滑。

8.3 温度缩放（Temperature Scaling）
对 $\text{logit}_{\text{cal}}$ 应用温度 $T>1$ 的缩放：
$$ \text{logit}_{\text{temp}} = \text{logit}_{\text{cal}}/T $$
以减小过度校准带来的过置信，提高整体阈值可分性并平衡 P/R。

8.4 α 下界（Floor）
在 OOD 场景中，若仅依据 $\alpha_F$ 或原型差分进行门控，可能导致过度抑制环境调制，造成召回显著下降。为此为 $\alpha$ 设置下界：
$$ \alpha(x,c) \leftarrow \text{clip}\big(\alpha(x,c),\,\alpha_{\min},\,1\big) $$
推荐取值区间 $\alpha_{\min}\in[0.2, 0.3]$，在保证环境许可的基础强度的同时，仍由混合门控决定相对强弱。

8.5 软置信回退（Soft Confidence Backoff）
相较于二值回退，使用平滑的软回退权重可更稳定地保护 PR 曲线。定义
$$ u_\alpha(x) = \sigma\big(k\,(\tau_\alpha - \alpha(x,c))\big),\quad u_I(x) = \sigma\big(k\,(\tau_I - I_{\text{approx}}(x))\big) $$
用概率和的“或”实现联合不置信：
$$ u(x) = 1 - \big(1 - u_\alpha(x)\big)\big(1 - u_I(x)\big) $$
最终融合：
$$ p_{\text{mix}}(x) = \big(1-u(x)\big)\,p_{\text{cal}}(x) + u(x)\,p_{\text{base}}(x) $$
其中 $k>0$ 控制过渡陡峭度，常取 $k\in[6,10]$。该设计在方向性信号不足时更平滑地回退到基线，提高召回并稳定 AUPR。

8.6 细胞系保守选择（Per-cell Conservative Selection）
评估阶段对每个细胞系同时计算基线概率 $p_{\text{base}}$、方向性校准概率 $p_{\text{cal}}$ 与软回退融合概率 $p_{\text{mix}}$，比较其 AUPR，选择分数更优的一种用于该细胞系的汇总与绘图。这一保守策略可在未知域上避免因错误校准造成的指标下降，同时保留在可校准细胞系上的增益。

9) 总体流程建议
1. 计算 $\alpha_\text{near},\alpha_\text{far},s_G,I_{\text{approx}}$，得到混合门控 $\alpha$。
2. 在 logit 空间做加性校准并做温度缩放得到 $\text{logit}_{\text{temp}}$。
3. 设置 $\alpha_{\min}$ 并按软置信回退得到 $p_{\text{mix}}$。
4. 逐细胞系在 $p_{\text{base}}, p_{\text{cal}}, p_{\text{mix}}$ 中保守选择 AUPR 更高者进行汇总与画图。

### 五、 总结

落实要点：

1. 冻结 Backbone，仅用旁路的 $z_G,z_F,z_I$ 与 GraphContext 的 $\mu_c$ 构造方向性门控 $\alpha$ 与交互偏置 $I_{\text{approx}}$。
2. 在评估与下游微调阶段，按批次统计标准化 $\|z_I\|$，以稳健方式注入偏置；所有操作在隐空间完成，避免 0/1 标签介入。
3. 在推理端使用 $\tilde{H}$ 与 $\ell$ 的闭式融合，并以原型混合与对数几率校准实现无监督的方向性迁移；评估期保守选择保证在 OOD 细胞系上不劣于基线。

### 六、 目标再定义：选择性风险最小化与锚定单调校准

在当前实验中，AUC 提升而 AUPR 与召回下降，表明排序优化但概率置信与阈值行为不稳。将“微调目标”从无约束的能量/熵最小化，提升为带有“保守锚定约束”的选择性风险最小化更为合理：

1) 选择性风险最小化（Selective Risk Minimization）
以基线概率 $p_{\text{base}}(x)$ 作为可靠先验，定义两端选择区域：
$$ \mathcal{A}_{\text{hi}} = \{x\mid p_{\text{base}}(x)\ge \tau_{\text{hi}}\},\quad \mathcal{A}_{\text{lo}} = \{x\mid p_{\text{base}}(x)\le \tau_{\text{lo}}\} $$
其中 $\tau_{\text{hi}}\in[0.7,0.85],\ \tau_{\text{lo}}\in[0.15,0.3]$。在 $\mathcal{A}_{\text{hi}}$ 内避免将高置信正例大幅压低；在 $\mathcal{A}_{\text{lo}}$ 且 $\alpha$ 低置信时避免将低置信负例大幅抬高。

2) 锚定单调校准（Anchored Monotone Calibration）
对方向性校准概率 $p_{\text{cal}}(x)$ 施加单调锚定约束：
$$ p_{\text{cal}}^{\star}(x) = \begin{cases}
\max\big(p_{\text{cal}}(x),\ p_{\text{base}}(x) - \delta_{\text{hi}}\big), & x\in\mathcal{A}_{\text{hi}} \\
\min\big(p_{\text{cal}}(x),\ p_{\text{base}}(x) + \delta_{\text{lo}}\big), & x\in\mathcal{A}_{\text{lo}}\ \wedge\ \alpha(x,c)<\tau_\alpha \\
p_{\text{cal}}(x), & \text{otherwise}
\end{cases} $$
其中 $\delta_{\text{hi}},\delta_{\text{lo}}\in[0.05,0.15]$ 为上下界松弛。该约束保持与基线排序相容的单调性，不让方向性调制在高置信区间“翻转”决策，从而保护 PR 面积与召回。

3) 推理闭式实现
不需训练，仅在推理端应用锚定裁剪与软回退：先进行对数几率加性校准与温度缩放得到 $p_{\text{cal}}$，再施加锚定得到 $p_{\text{cal}}^{\star}$，最后按软置信回退与细胞系保守选择得到最终分数用于评估。

4) 理性依据
- 生物化学不变性：基线背靠冻结主干的序列兼容先验，应在高置信区间保持“不可被轻易推翻”的单调锚定。
- 领域不确定性：在低置信且门控低的区域，方向性调制不应造成过度抬高，避免误报导致 PR 面积下滑。
- 评估稳健性：细胞系级保守选择与软回退合用，能在未知域上维持不劣于基线的下限，同时保留可校准域的增益。
