目标：在无标签下游环境中，不重新训练主干，仅基于已训练的旁路解耦权重，利用 OOD 细胞系的共性 G 与特性 F 的分布，方向性地偏置迁移已有知识，近似得到 EP 交互 I，并提升最终 EP 判定的鲁棒性与准确性。

---

### 一、 EP 互作的概率分解模型 (The Probability Decomposition)

我们将 $P(y=1 | x_E, x_P, c)$ 分解为两个相互独立的因子：

$$ P(y=1) \approx P(\text{Compatible} | x_E, x_P) \times P(\text{Active} | x_E, x_P, M_{cell}) $$

1.  **$P(\text{Compatible})$ [由 Backbone 负责]**：
    *   这是序列层面的硬约束（Hard Constraint）。
    *   例如：Enhancer 和 Promoter 是否拥有匹配的转录因子结合位点？DNA 环化（Looping）的结构基础是否存在？
    *   **数学性质**：这是 **跨细胞系不变 (Invariant)** 的。你的 Backbone 已经在预训练中学会了这一点，这是它能达到 60% 的基础。

2.  **$P(\text{Active})$ [由 Bypass + FiLM 负责]**：
    *   这是环境层面的软约束（Soft Constraint）。
    *   例如：在这个细胞系中，这些位点是否处于开放染色质区域（Open Chromatin）？相关的 TF 是否表达？
    *   **数学性质**：这是 **环境敏感 (Context-Sensitive)** 的。这正是 60% -> 75% 的增量来源。

结论：下游适应必须冻结 Backbone，仅在隐变量层面调整环境参数，不可用 0/1 标签直接回传至 Backbone。

---

### 二、 为什么直接使用 0/1 更新不可行？ (The Failure of Binary Supervision)

假设下游任务是一个全新的细胞系 $C_{new}$。
如果是一个正样本 $(x_E, x_P, y=1)$：
*   模型需要 $P(\text{Compatible}) \uparrow$ 且 $P(\text{Active}) \uparrow$。
*   这没问题，梯度会强化两者。

**但如果是一个负样本 $(x_E, x_P, y=0)$：**
*   这才是问题的关键。负样本有两种情况：
    *   **Case A (结构不匹配)**：序列根本不搭。此时 $P(\text{Compatible}) \approx 0$。
    *   **Case B (环境抑制)**：序列完美匹配，但染色质关闭。此时 $P(\text{Compatible}) \approx 1$，但 $P(\text{Active}) \approx 0$。
*   在 Hard Negative Mining 中，**Case B 占绝大多数**。
*   如果你直接用 $y=0$ 回传梯度更新 Backbone，你会强行压低 $P(\text{Compatible})$。
*   **数学后果**：模型学会了“在这个细胞系里，这个 Motif 组合是错的”。但这违反了生物化学原理（Motif 结合是物理属性）。当你换一个细胞系（该区域开放）时，模型就会误判。

**结论**：在下游适应时，**必须锁定 $P(\text{Compatible})$（即冻结 Backbone）**，仅允许梯度去寻找使得 $P(\text{Active}) \approx 0$ 的环境参数 $M_{cell}$。

---

### 三、 适应性训练的数学目标：能量最小化 (Energy Minimization)

我们适应的是环境隐变量 $M_{cell}$，以能量最小化视角进行变分推断。

定义系统的 **自由能 (Free Energy)** $F(x, M)$。
对于下游的一批无标签数据 $X_{batch}$，我们假设它们服从某种潜在的生物学规律。我们寻找最优的 $M^*$ 来解释这些观测数据。

#### 1. 互作一致性势能 (Interaction Consistency Potential)
EP 互作不是随机的，它具有稀疏性和聚集性。
Backbone 输出的特征向量 $h_E, h_P$ 包含序列信息。
$$ \mathcal{L}_{align} = - \sum_{i} \text{Sim}(h_{E_i}, h_{P_i}) \cdot \mathcal{G}(M) $$
这不够。我们需要利用你 `decouple.py` 中的 $I$ (Interaction) 分量。
在 Bypass 中，我们有一个 $z_I$。
对于同一个 batch 的数据，如果 Backbone 认为它们“很像互作”（$P(\text{Compatible})$ 高），而当前的 $M$ 导致 $P(\text{Active})$ 很低，这就产生了 **认知失调 (Cognitive Dissonance)** 或 **高能量状态**。

适应目标：
$$ M^* = \arg\min_M \left( \mathcal{H}(\hat{y}(x, M)) + \lambda \cdot D_{KL}(M || \mathcal{M}_{GCN}) \right) $$

*   **$\mathcal{H}(\hat{y})$ (熵最小化)**：
    *   如果 $M$ 是错误的（例如把 K562 当成了 GM12878），FiLM 会进行错误的调制，导致 Backbone 的特征变得混乱，最终预测值 $\hat{y}$ 会徘徊在 0.5 左右（不确定）。
    *   如果 $M$ 是正确的，它会精准地通过 FiLM 抑制那些“本细胞系不开放”的噪音，放大真正的信号，使得 $\hat{y}$ 趋向 0 或 1。
    *   **这就是 60% -> 75% 的数学原理：通过正确的 $M$ 过滤掉 Case B 类的假阳性，大幅提升 Precision，从而提升 AUC/AUPR。**

*   **流形约束**：$M$ 必须位于 GraphContext 学到的细胞系流形 $\mathcal{M}_{GCN}$ 上。

---

### 四、 针对 EP 互作的鲁棒性最大化设计

方向性偏置迁移的核心是构造一个来自 $G/F$ 的门控系数 $\alpha(x,c) \in [0,1]$，作为环境许可度，对 Backbone 的序列互作势能进行调制，并从 $z_I$ 导出近似 EP 交互强度。

1) 环境门控（基于 F 原型的 RBF 对齐）：
设 GraphContext 给出目标细胞原型 $\mu_c$，则对样本 $x$ 的特性向量 $z_F(x)$ 定义
$$ \alpha_F(x,c) = \exp\left(-\frac{\|z_F(x) - \mu_c\|^2}{\tau_F}\right) $$
其中 $\tau_F>0$ 为温度超参数。$\alpha_F$ 越大，表示样本与当前细胞环境越一致，越应当允许环境调制。

2) 共性校准（可选）：
以全局共性均值 $\bar{z}_G$ 进行余弦相似度校准
$$ s_G(x) = \max\{\cos(z_G(x), \bar{z}_G), 0\} $$
令 $\alpha(x,c) = \alpha_F(x,c) \cdot \big(\beta_0 + \beta_1 s_G(x)\big)$，$\beta_0,\beta_1 \ge 0$。

3) 交互近似（来源于 $z_I$ 的规范化强度）：
定义
$$ I_{\text{approx}}(x) = \sigma\Big(\kappa\cdot \frac{\|z_I(x)\| - m_I}{s_I + \varepsilon}\Big) $$
其中 $m_I,s_I$ 分别为当前批次 $\|z_I\|$ 的均值与标准差，$\kappa>0$ 控制斜率，$\sigma$ 为 Sigmoid。

4) 融合算子（FiLM 的方向性门控与交互偏置）：
记 Backbone 特征为 $H(x)$，旁路产生的 FiLM 参数为 $\gamma(M),\beta(M)$，则
$$ \tilde{H}(x,c) = (1-\alpha(x,c))\cdot H(x) + \alpha(x,c)\cdot (\gamma\odot H(x) + \beta) $$
最终判定的对数几率近似为
$$ \ell(x,c) = f_{\text{KAN}}\big(\tilde{H}(x,c)\big) + \lambda_I\cdot \big(I_{\text{approx}}(x) - \tfrac{1}{2}\big) $$
其中 $f_{\text{KAN}}$ 为 FourierKAN 头，$\lambda_I$ 为小权重，将 $z_I$ 的交互强度作为方向性偏置注入到决策中。输出概率为 $\hat{y}(x,c) = \sigma(\ell(x,c))$。

该方案仅依赖已训练旁路的 $z_G,z_F,z_I,\mu_c$ 与 FiLM 映射，不需要重新训练主干；$\alpha$ 与 $I_{\text{approx}}$ 完全由统计与几何关系给出，具备明确的方向性：当样本的 $z_F$ 明显偏离目标细胞原型时，降低环境调制权重，避免将环境许可错误地施加到不匹配的序列；当 $\|z_I\|$ 较大时，通过轻量的偏置提升对高兼容样本的置信度，从而在难测试集中显著抑制假阳性并提升 AUPR/AUC。

### 五、 总结

落实要点：

1. 冻结 Backbone，仅用旁路的 $z_G,z_F,z_I$ 与 GraphContext 的 $\mu_c$ 构造方向性门控 $\alpha$ 与交互偏置 $I_{\text{approx}}$。
2. 在评估与下游微调阶段，按批次统计标准化 $\|z_I\|$，以稳健方式注入偏置；所有操作在隐空间完成，避免 0/1 标签介入。
3. 在推理端使用 $\tilde{H}$ 与 $\ell$ 的闭式融合，实现无监督的方向性迁移，从而将已训练权重的知识迁移为对 OOD 细胞系的 EP 判定增益。
