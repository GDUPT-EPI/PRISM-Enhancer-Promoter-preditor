# 记录点8反思：元学习范式的崩塌与模式坍缩

## 1. 核心问题复盘
在记录点8中，我们引入了“学生竞争机制”和“强制上下文依赖”，试图通过元学习（Meta-Learning）让模型具备在未见细胞系上的泛化能力。然而，实验结果显示 AUPR 暴跌至 0.53 (GM12878)，且模型出现了严重的**模式坍缩 (Mode Collapse)**。

### 1.1 现象
- **预测值趋同**：模型对所有样本的预测概率趋向于一个固定的先验分布（如 0.1 或 0.5），失去了区分正负样本的能力。
- **环境阻力失效**：Student 模块生成的环境阻力 $R_E$ 无法正确反映当前细胞系的特异性，变成了一个无效的常数偏置。

## 2. 根因分析 (Root Cause Analysis)

### 2.1 数据流的根本矛盾：随机采样 vs. 上下文推理
我们试图让 Student 从当前的 Batch 中推断出环境信息（Environment Context）。然而，训练中使用的 `RandomBatchSampler` 导致每个 Batch 包含了来自不同细胞系的混合样本。
- **混合分布噪声**：Student 面对的是一个“大杂烩”上下文（Context）。试图从包含 K562、GM12878、HEK293 等混合样本的集合中，推断出某一个特定细胞系的 $R_E$，在数学上是一个**不适定问题 (Ill-posed Problem)**。
- **平均化效应**：为了最小化损失，Student 被迫学习所有细胞系的“平均阻力”，导致 $R_E$ 失去特异性，进而导致最终预测 $P(y|x)$ 退化为平均概率。

### 2.2 教师-学生博弈的纳什均衡陷阱
我们设计的 Teacher-Student-Opportunist 竞争机制，本意是促进信息解耦。但在缺乏全局流形约束（Global Manifold Constraint）的情况下，三者达到了一个低效的纳什均衡：
- **Teacher (查表)**：简单地记住了训练集的偏置。
- **Student (盲猜)**：由于输入上下文是噪声（混合Batch），Student 放弃了推理，直接输出 0 或常数。
- **结果**：$U_I$（固有电势）被迫承担所有拟合任务，但由于缺乏 $R_E$ 的有效调节，模型退化回了普通的 MLP，且因为增加了无效的参数干扰，性能反而不如 Baseline。

## 3. 痛定思痛：修正方向

### 3.1 必须实施同质化采样 (Homogeneous Sampling)
**Meta-Learning 的前提是 Task 的清晰定义。**
在我们的场景中，**一个 Task = 一个细胞系**。
必须废弃 `RandomBatchSampler`，严格执行 `HomogeneousBatchSampler`（或 `CellBatchSampler`）。即：**一个 Batch 内的所有样本必须来自同一个细胞系**。只有这样，Student 看到的 Support Set 才是纯净的，才能从中提取出该细胞系的分布特征（均值、方差、高阶矩）。

### 3.2 从“竞争”转向“对齐” (Alignment)
单纯的竞争导致了训练的不稳定。我们需要引入上帝视角（God's Eye View）来指导 Student。
- **Teacher**：不应只是查表，而应基于**全局细胞系图谱 (Cell Prototype Graph)** 构建全局流形。它知道所有细胞系的关系。
- **Student**：在测试时看不到全局图谱，只能看到当前的 Support Set。它的目标是**将当前的 Support Set 映射到 Teacher 构建的全局流形上**。
- **目标函数**：从 Min-Max 对抗转向 **Manifold Alignment (流形对齐)**。

## 4. 结论
记录点8的失败不是“上下文依赖”这一理念的错误，而是**实现方式与数据流逻辑的错位**。
**“由于输入数据的混合性，强行要求模型从噪声中提取秩序，导致了模型的习得性无助。”**

下一步（记录点9）的核心任务：**重构数据流（同质化采样）** + **构建全局流形约束（Graph Teacher）**。
