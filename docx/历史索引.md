**历史经验记录**
- 记录点1：
- 将原始 cross attn 替换为 CBAT（含二维重排与块因果掩码、硬 Top‑k、自适应损失），并在 `PRISMBackbone` 中合并 `[P;E]` 输入以实现 `E←P`，掩码屏蔽 `E→E`。
- 上次问题：
  - 硬 Top‑k 导致未选 token 输出为零，排名断裂，AUPR/AUC下滑。
  - 二维重排引入网格化假设与硬边界，损害序列语义与长程对齐。
  - 门控饱和（Sigmoid靠近0/1）使概率整体上移，Recall↑ Precision↓。
  - 仅单向 `E←P` 缺少补偿，跨域稳健性不足。
- 上次结论：需要替代2D重排、软化稀疏、门控温控、小残差、锚点引导与双向协同，以提升未见细胞上的排序稳健性与AUPR/AUC。

- 记录点2：
  - 用一维多尺度卷积金字塔替代二维重排，输出保持 `[B,L,D]`。
  - `RoPE_CausalBlockAttention` 增加 `use_block_mask/window_size`，默认窗口掩码，弱化硬边界。
  - `RoPE_AdaptAttention` 改为温度软稀疏（列偏置），不再零填未选列，保留排序连续性。
  - `gate_1/gate_2` 加入温度控制与小系数残差，抑制概率上移。
  - `PRISMBackbone` 在池化处引入 `P` 的锚点温度，降低峰值放大。
- 结果：在若干细胞系上 AUPR/AUC 较旧版上升、与 cross attn 接近或略低；Recall回落、Precision上升，F1与 cross attn 接近。
- 反思：仍需加强全局对齐通道、引入双向协同与锚点参与注意力、进一步约束门控与稀疏，以在未见细胞上提升排序稳健性并超过 cross attn。

- 记录点3：
  - **Prototype Routing Attention (PRA)**：彻底抛弃直接 Attention，改为 $E \to \text{Proto} \to P$ 的路由机制，引入 $K=64$ 个原型向量。
  - **Local Context Encoder (LCE)**：使用 Depthwise Conv 提取局部 Motif 特征，替代金字塔卷积。
- **本次结果**：
  - AUPR/AUC 较记录点2和Baseline均有下滑（如 GM12878 AUPR 0.66 -> 0.65）。
  - 模型置信度分化严重（倾向于0/1），导致 Ranking 能力下降。
  - 未见细胞系泛化能力未达预期，信息瓶颈导致特异性信号丢失。
- **反思**：
  - **过度压缩**：路由机制引入了强信息瓶颈，丢失了 E-P 互作的序列细节和组合特征。
  - **原型平均化**：原型仅捕获了共性模式，无法处理决定互作的关键稀有突变。
  - **缺乏校验**：缺少 Query-Key 直接校验，导致只要匹配同一原型即判定互作，产生高置信度假阳性。
- **结论**：
  - 必须回归 $E-P$ 直接交互以保留细节。
  - 原型应作为**引导（Guide）**而非**瓶颈（Bottleneck）**。
  - 下一步需设计“双流机制”，结合全局直接交互与原型语义引导。

- 记录点4：
  - **双向CBAT + 锚点参与**：在主干中并行 `E←P` 与 `P←E` 两个跨序分支，并在池化处使用可学习锚点温度与方向门控融合（models/PRISMModel.py:382-447）。
  - **两级交互路径**：多尺度卷积、局部块注意力、软稀疏列偏置与双门控融合的 CBAT（models/layers/attn.py:600-888）。
  - **能量头与域对抗**：用 `FourierEnergyKAN` 生成内势 `U_I`，并以 GRL+判别器清洗域信息（models/PRISMModel.py:259-278, 456-475）。
  - **结果**：AUPR/AUC全面提升，但置信度显著上移，阈值偏高；NHEK 出现 Recall≈1.0 与 Precision≈0.50 的极端失衡。
  - **反思**：列偏置直接加到注意力 logits 使 Key 先验跨 Query 过强；`U_I` 未校准导致概率整体上移；稀疏温度缺少退火与熵约束致单峰化。需改为“偏置轻量化+输出校准+稀疏退火”。

- 记录点5：
  - **对记录点4的回退尝试**：试图通过简单的逻辑回退来修复置信度问题，但未触及根本。
  - **核心问题分析**：
    - **无界势能误用**：物理势能 $U_I$ 未经缩放直接作为 Logits，导致 Sigmoid 极易饱和。
    - **环境信息丢失**：GRL 对抗训练过于彻底，剔除了所有环境信息，导致模型在预测时缺乏特异性。
    - **阻抗模块缺失**：理论上的 $U_I - R_E$ 模型在代码中只实现了 $U_I$，缺失了关键的 $R_E$（环境阻抗）。
  - **结果**：置信度极化问题未解决，Recall 依然极高，Precision 依然极低。
  - **结论**：必须构建完整的**能量耗散系统**，即 $P(y=1) = \sigma((U_I - R_E)/T)$，并引入温度系数 $T$ 进行校准。

- 记录点7：
  - **学生-投机者竞争机制 (Student-Opportunist Competition)**：构建了 Teacher（使用细胞ID）、Student（使用 ISAB 上下文）、Opportunist（使用统计特征）的蒸馏对抗框架。
  - **核心理念**：通过 Student 模仿 Teacher 的行为，学习从 Batch 上下文中提取环境阻抗 $R_E$，从而摆脱对静态细胞 ID 的依赖。
  - **结果**：
    - **AUPR 倒退**：AUPR 未能突破 70% 瓶颈，反而在 GM12878 (0.6364) 等细胞系上相比记录点4 (0.6853) 显著下降。
    - **机制失效**：Student 模块未能如期提取有效上下文，竞争机制退化为简单的特征融合。
  - **根因反思**：
    - **单样本谬误**：实现上依然是 `Single Feature -> Decision` 的单样本流，上下文只是附加项，未形成根本依赖。
    - **随机采样灾难**：训练时使用 `RandomBatchSampler`，导致 Batch 内混合了不同细胞系的样本，Student 学到的是噪声而非分布特征。
    - **逻辑颠倒**：模型在没有上下文的情况下依然能做出判断（单样本泄露），违背了“先有上下文后有判断”的原则。
  - **结论**：必须重构为**强制上下文依赖（Context-First）**架构，并配合**同质化采样（Homogeneous Sampling）**，将问题转化为元学习（Meta-Learning）/上下文学习（In-Context Learning）范式。

- 记录点8：
  - **元学习与强制上下文依赖 (Meta-Learning & Forced Context Dependency)**：尝试通过强制模型 $P(y|x, S)$ 依赖 Support Set $S$ 来进行推理。
  - **结果**：**模式坍缩 (Mode Collapse)**，AUPR 跌至 0.53，模型退化为盲目猜测。
  - **根因反思**：
    - **数据流错位**：在 `RandomBatchSampler` 产生的混合 Batch 上强行进行 Context Learning，导致 Context 变为高斯噪声，Student 习得性无助。
    - **博弈纳什均衡陷阱**：Teacher 查表、Student 躺平、Opportunist 乱猜，系统收敛到一个低效的均衡点。
  - 结论：Meta-Learning 的前提是 Task 定义清晰。必须引入**同质化采样 (Homogeneous Sampling)** 和 **全局流形约束 (Global Manifold Constraint)**，将竞争转为对齐 (Alignment)。

- 记录点9：
  - **元批次采样与随机图片池 (Meta-Batch Sampling with Random Block Pool)**：实施了将同质化样本打包成 Block，但允许不同细胞系的 Block 在 Batch 内随机混合。
  - **结果**：**模式坍缩持续 (Persistent Mode Collapse)**，AUPR 与记录点8 一致 (0.53)，Recall=1.0，Precision=0.5。
  - **根因反思**：
    - **噪声混合陷阱**：Batch 内 Block 的随机混合导致 Student 的 Context 成为混合分布，退化为全局平均，丢失了细胞特异性。
    - **Teacher 懒惰查表**：Teacher 依赖 ID 查表，过于强大；Student 面对混合 Context 无法拟合 Teacher，竞争机制失效。
  - **结论**：
    - 仅靠物理采样调整不足以解决问题，必须引入**全局细胞系原型图 (Cell Prototype Graph)** 提供强先验。
    - 需从 **Competition (竞争)** 转向 **Manifold Alignment (流形对齐)**，并确保 Student 输入的逻辑纯净性。

- 记录点10：
  - **CED-Net 架构尝试**：实现了 Teacher-Student-Opportunist 竞争架构，旨在通过 Student 学习鲁棒的环境特征。
  - **结果**：**模式坍缩 (Mode Collapse)**，AUPR 停滞在 0.55-0.58，F1 分数极低。
  - **根因反思**：
    - **预测端断裂 (Inference Disconnect)**：训练时虽然构建了复杂的 CED-Net，但在预测时 (`predict.py`) 却完全未调用 Student 模块，且未构建 Context Batch。
    - **环境失明 (Context Blindness)**：模型在推理时退化为仅依赖 $U_I$ 的“盲猜”模式，丢失了所有环境特异性信息。
    - **认知偏差**：误以为训练时的对抗就能自动带来泛化，忽略了 OOD 泛化需要推理时的显式适应 (Explicit Adaptation)。
  - **结论**：
    - 必须重构预测流程，使其支持 Context-Aware Inference。
    - 预测时必须按细胞系组织 Batch，并显式调用 Student 模块生成环境阻抗 $R_E$。

- 记录点11：
  - **CED-Net + 能量耗散整合 (v1)**：在 `PRISMBackbone` 中接入 Teacher-Student-Opportunist、解耦对抗算子与 $U_I-R_E$ 能量头，训练集 AUPR/AUC 提升到 0.85–0.92 / 0.86–0.88。
  - **结果**：domain-kl/test 上出现严重模式坍塌（AUPR/AUC≈0.51–0.53，F1 极低），各细胞系表现接近随机。
  - **根因反思**：
    - 训练在混合细胞系 Meta-Batch 上最小化蒸馏与竞争损失，而评估是在按细胞系分组的 OOD 任务上，任务定义不一致。
    - Student 模块只在训练损失中起作用，主预测路径仍为 $P(y=1)=σ((U_I−R_E)/T)$，且 R_E 主要由 `BypassDecoupler(z_I)` 给出，未真正利用“从分布中推断环境”的能力。
    - U_I 被卷入 Push-away 和蒸馏博弈，丧失应保持的稳定排序能力，输出整体收缩到近似常数。
  - **结论**：问题不在于 CED-Net 或能量耗散思想，而在于过多复杂目标叠加在同一条数据流上，同时训练/推理数据形式和能量公式不一致，导致模型在实战推理时退化为“安全但无用”的平凡解。

- 记录点12：
  - **CellBatchSampler + 现有 CED-Net 实现的系统训练**：采用同质化按细胞系采样，并配合最新 `predict.py` 的 context-aware 推理，在完整数据集上长程训练。
  - **结果**：训练集 AUPR 从 0.56 升至约 0.76，AUC 约 0.75，但 domain-kl/test AUPR/AUC 仍贴近 0.51–0.53，整体性能停滞。
  - **根因反思**：
    - 采样与推理流程虽有所改进，但 U_I/R_E 物理角色颠倒、Student/Teacher 数据流纠缠等结构问题未解决。
    - 多个正交、对抗、蒸馏、竞赛损失同时作用于单一路径，进一步稀释了对“排序 + 环境纠偏”真正有用的梯度信号。
  - **结论**：单纯延长训练和调参无法扭转架构性的模式坍塌，必须回到设计层面对能量分解与竞争机制做系统性重审。

- 记录点13：
  - **自杀式对抗训练 (Suicidal Adversarial Training)**：Pull 损失恒为 0，Push 损失使得 S2 随机猜测，S1 轻松获胜但未受挑战。
  - **结果**：没有模式坍缩，但 S2 学习效率极低，AUPR (0.66) 远低于目标 (0.80)。
  - **根因反思**：
    - **梯度流向错误**：Push Loss 直接惩罚 S2 的预测能力（Maximize Loss），导致 S2 无法变强，进而无法迫使 Backbone 剥离捷径。
    - **对抗机制缺失**：缺乏 GRL (Gradient Reversal Layer)，Backbone 和 S2 变成了“互相伤害”而非“猫鼠游戏”。
  - **结论**：必须引入 **GRL 单向阀**，确保 S2 永远只做最小化 Loss 的优化，而 Backbone 通过梯度反转来最大化 S2 的 Loss。

- 记录点15：
  - **修复变分贝叶斯损失函数维度不匹配错误**：修复记录点14实现中的维度不匹配问题，完成训练与预测。
  - **结果**：domain-kl/test AUPR 0.6962，AUC 0.7093，F1 0.6910；各细胞系AUPR 0.6588 (NHEK) ~ 0.7221 (Stomach)。
  - **关键问题**：过拟合严重（训练集0.9699 vs 测试集0.6962）；NHEK细胞系Recall 0.9873，Precision 0.5040，阈值偏低(0.46)。
  - **反思结论**：变分框架在先验过拟合时失效；需要更强的先验约束（分层、图结构）、信息理论解耦、自监督适应。

- 记录点16：
  - **图约束分层变分推断与信息瓶颈解耦**：引入细胞系图先验（GCN编码相似性）、分层贝叶斯结构、信息瓶颈强制特征解耦、自监督测试时适应。
  - **核心创新**：图先验提供连续流形归纳偏置；分层KL防止先验过拟合；信息瓶颈保证$z_I \perp C$，$z_E \not\perp C$；图插值适应未知细胞系。
  - **状态**：设计完成
  - **预期**：解决过拟合，提升泛化，AUPR目标 ≥ 0.75。
  - **进一步优化训练过程**：训练中出现负损失（-2.8727），可能损失计算或权重设置有问题。
  - **结果**：训练AUPR达到0.9737，但测试性能未知（未找到对应compete结果）。
  - **反思**：损失函数异常可能影响模型学习，需要检查损失计算逻辑。

- 记录点17：
  - **基于记录点15的继续训练**：使用纯随机批次，损失权重ep=1.0, orth=0.1, domain=0.1, sparse=0.01。
  - **结果**：domain-kl/test AUPR=0.6764，AUC=0.6985，性能较记录点15下降。
  - **关键问题**：Recall过高（0.8648），Precision过低（0.5663），阈值偏低（0.05-0.14），泛化差距大（训练AUPR 0.9656 vs 测试 0.6764）。
  - **根因反思**：环境阻抗估计失效退化为常数偏置，温度未校准，导致模型退化为高Recall平凡分类器。
  - **结论**：需要因果阻抗分解、自适应温度学习和对比不变性学习。

- 记录点18：
  - **核心方案**：沿用能量耗散框架与域对抗训练，批量大小64，训练7轮，损失权重 ep=1.0, orth=0.1, domain=0.1, sparse=0.01。
  - **结果**：训练AUPR高达0.9770，但domain-kl/test AUPR仅0.6843，泛化差距巨大（0.293）。Recall 0.4987, Precision 0.7135，阈值极低（0.01）。
  - **根因反思**：
    - **过拟合训练细胞系特有模式**：模型容量过大，Rademacher复杂度高，缺乏不变性归纳偏置。
    - **能量分解物理基础不牢**：$U_I$与$R_E$的分解缺乏生物学约束，导致任意性。
    - **对抗训练博弈不平衡**：GRL可能过度消除细胞系信息或消除不足。
  - **结论**：必须注入结构性的拓扑先验，强制模型分离细胞系变异与核心互作信号。

- 记录点19：
  - **方案核心**：拓扑不变能量耗散网络 (TIED-Net)，引入保守染色质接触图作为不变性锚点，将阻抗分解为全局基线$R_{\text{base}}(c)$与局部拓扑$R_{\text{topo}}(x,c)$。
  - **创新点**：利用Hi-C衍生的拓扑图提供跨细胞系不变的物理约束，乘以细胞系特异的表观可及性调制，实现可解释的能量分解。
  - **状态**：设计完成
  - **结果**：待训练与评估
  - **预期**：通过拓扑先验降低假设空间复杂度，缩小泛化差距，目标AUPR ≥ 0.75。

- 记录点20：
  - **方案核心**：对比不变性能量网络 (CIEN)，通过监督对比损失与条件对抗训练最小化条件互信息 $I(\Phi(x); c \mid y)$，学习细胞系不变的因果表示。
  - **创新点**：首次直接优化条件互信息，结合对比学习（类内聚集）与条件对抗（给定标签下去除细胞系信息），实现内蕴不变性学习。
  - **状态**：已完成
  - **结果**：AUPR 0.6896, AUC 0.6928, Recall 0.8639, Precision 0.5439。未达目标 (≥0.75)。
  - **反思**：条件互信息最小化不彻底，对比聚集性不足，Recall-Precision严重失衡延续。根本偏置未解决。
  - **结论**：需要更激进的结构性干预，直接约束决策边界几何，而非仅优化表示。

- 记录点21：
  - **方案核心**：因果锚定排序能量网络 (CAREN)，通过锚定参照细胞系阻抗为零、不变风险最小化(IRM)、配对排序损失与反事实正则化，打破平移对称性、强化因果不变性并直接优化排序能力。
  - **创新点**：首次将锚定分解、IRM、排序损失与反事实正则结合，系统解决能量框架的对称性、因果性、排序对齐问题。
  - **状态**：设计完成
  - **预期**：AUPR提升至≥0.75，泛化差距缩小至≤0.15，Recall-Precision平衡改善。
  - **理论依据**：平移对称性破缺、因果不变风险最小化、排序优化理论。
