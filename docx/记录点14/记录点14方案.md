记录点14方案：复活机会主义者 (Rehabilitating the Opportunist)

一、背景与目标
- **背景**：在记录点13中，由于 Push Loss 的逻辑错误（试图最大化 S2 Loss）以及梯度流向问题，Opportunist (S2) 被彻底摧毁，导致 Pull Loss 恒为 0，Master (S1) 失去了竞争对手，最终过拟合。
- **目标**：重建健康的 S1 vs S2 竞争关系。S2 必须足够强（能快速利用捷径），才能逼迫 S1 学习更鲁棒的特征。
- **核心策略**：停止打压 S2，改为“S2 全力跑，S1 拼命追”。

二、具体修改方案

1. **修正梯度流向 (Gradient Flow Correction)**
   - **S2 (Opportunist)**：
     - 输入必须 `detach()`。S2 不应有权修改 Backbone 的参数来迎合自己的捷径需求。
     - S2 只能利用 Backbone 提供的现有特征（z_I, z_F）来寻找捷径。
     - 代码修改：`s2_logits, s2_feat = self.student2(z_I.detach(), z_F.detach())`
   - **S1 (Master)**：
     - 输入保持**不** `detach()`。S1 必须能够驱动 Backbone 学习出更好的 z_I，以在根本上超越 S2。

2. **移除自杀式 Push Loss**
   - **原逻辑**：当 S1 > S2 时，最大化 S2 Loss。 -> **错误**，导致 S2 变傻。
   - **新逻辑**：**移除 Push Loss**（设权重为 0）。
     - S2 的唯一目标就是最小化自己的分类损失（BCE）。
     - S2 应当是一个贪婪的、聪明的、利用一切可用信息的“坏学生”。
     - 只有 S2 足够聪明，S1 超过 S2 才是有意义的。

3. **增强 S2 能力**
   - **原设计**：S2 隐藏层维度减半，使用 ReLU。
   - **新设计**：
     - S2 隐藏层维度与 S1 保持一致（`d_model`）。
     - 激活函数升级为 `GELU`。
     - 甚至可以考虑让 S2 使用更激进的学习率（但暂不引入额外的优化器复杂度，先靠结构增强）。
     - 目的：确保 S2 在训练初期能迅速下降 Loss，从而尽早触发 `loss_s1 > loss_s2`，激活 Pull Loss。

4. **Pull Loss 逻辑确认**
   - `l_pull = ReLU(loss_s1 - loss_s2)`
   - 当 S2（利用捷径）跑得比 S1 快时，产生 Pull Loss。
   - 优化 S1 以减小 `loss_s1`（追赶 S2）。
   - 由于 S2 输入被 detach，Pull Loss 的梯度只会回传给 S1 和 Backbone，迫使 Backbone 提取更好的特征来降低 `loss_s1`。

三、预期结果
1. **训练初期**：S2 Loss 快速下降（因为它专注于捷径，且不再受 Push 干扰）。
2. **Pull 激活**：`loss_s1 > loss_s2` 出现，`pull` 项不再为 0。
3. **良性竞争**：S1 在 Pull 的驱动下加速学习，最终在 AUPR 上赶超 S2。
4. **泛化提升**：由于 S1 是在“不依赖捷径（因为捷径被 S2 占了，或者 S1 必须比 S2 更好）”的压力下胜出的，其特征应更具鲁棒性。

四、验证标准
- 训练日志中 `pull` 不再恒为 0。
- S2 的 AUPR 应该是一个正常的、较高的数值（例如 0.7-0.8），而不是随机猜测。
- S1 的 Test AUPR 超过 S2，且超过记录点13的 0.66。
