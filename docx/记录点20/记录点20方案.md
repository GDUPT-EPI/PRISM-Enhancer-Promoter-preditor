# 记录点20 方案：对比不变性能量网络 (Contrastive Invariant Energy Network, CIEN)

## 核心洞察（一句话）
**EP互作的跨细胞系泛化失败源于模型无法分离细胞系特异的虚假相关与因果序列特征，数学上表现为条件互信息 $I(\Phi(x); c \mid y) > 0$；通过对比学习与条件对抗训练最小化该条件互信息，可学习细胞系不变的因果表示，从而缩小泛化差距。**

## 问题的数学形式化

设 $x = (s_e, s_p)$ 为增强子-启动子序列对，$c \in \mathcal{C}$ 为细胞系标签，$y \in \{0,1\}$ 为互作标签。目标：学习 $P(y=1 \mid x, c)$。

当前能量框架：$P(y=1 \mid x, c) = \sigma((U_I(x) - R_E(c)) / T)$，其中 $U_I$ 为内势（序列亲和力），$R_E$ 为环境阻抗（细胞系特异性），$T$ 为温度。

**根本缺陷**：
1. **分解任意性**：对任意常数 $a$，$(U_I, R_E)$ 与 $(U_I + a, R_E + a)$ 给出相同预测，导致分解不可识别。
2. **不变性缺失**：$U_I(x)$ 未受跨细胞系不变性约束，可能编码细胞系特异的伪特征。

从信息论视角，理想表示 $\Phi(x)$ 应满足：
- **充分性**：$I(\Phi(x); y)$ 最大（保留预测信息）。
- **不变性**：$I(\Phi(x); c \mid y) = 0$（给定标签 $y$ 后，表示与细胞系无关）。

当前模型仅通过无条件对抗训练最小化 $I(\Phi(x); c)$，可能过度消除信息或消除不足。条件互信息 $I(\Phi(x); c \mid y)$ 更精确：允许 $\Phi(x)$ 与 $c$ 相关，但该相关性必须完全由 $y$ 介导。

## 解决方案

### 数学描述

#### 1. 架构基础
沿用能量耗散框架：
$$
P(y=1 \mid x, c) = \sigma\left(\frac{U_I(\Phi(x)) - R_E(c)}{T}\right)
$$
其中：
- $\Phi: \mathcal{X} \to \mathbb{R}^d$ 为序列编码器（现有 PRISMBackbone）。
- $U_I: \mathbb{R}^d \to \mathbb{R}$ 为内势头（FourierEnergyKAN）。
- $R_E: \mathcal{C} \to \mathbb{R}$ 为环境阻抗查找表。
- $T > 0$ 为可学习温度。

#### 2. 不变性正则化
引入两个正则化项强制条件独立性 $y \perp c \mid \Phi(x)$。

**(a) 监督对比损失 (SupCon)**
对于批次 $\mathcal{B} = \{(x_i, y_i, c_i)\}_{i=1}^N$，定义归一化表示 $z_i = \Phi(x_i) / \|\Phi(x_i)\|_2$。

对于锚样本 $i$，正例集合 $\mathcal{P}_i = \{j \in \mathcal{B} \mid y_j = y_i\}$（包括自身），负例集合 $\mathcal{N}_i = \{j \in \mathcal{B} \mid y_j \neq y_i\}$。

对比损失：
$$
\mathcal{L}_{\text{cont}} = \frac{1}{N} \sum_{i=1}^N \frac{-1}{|\mathcal{P}_i|} \sum_{j \in \mathcal{P}_i} \log \frac{\exp(z_i \cdot z_j / \tau)}{\sum_{k \neq i} \exp(z_i \cdot z_k / \tau)}
$$
其中 $\tau > 0$ 为温度超参。

**机制**：拉近同一类别样本的表示（无论细胞系），推远不同类别样本。这直接鼓励跨细胞系的类内一致性，隐含地最小化 $I(\Phi(x); c \mid y)$。

**(b) 条件对抗训练 (Conditional Adversarial Training)**
训练条件判别器 $D: \mathbb{R}^d \times \{0,1\} \to \Delta^{|\mathcal{C}|-1}$，输入表示 $z$ 与标签 $y$，输出细胞系概率分布。

判别器损失：
$$
\mathcal{L}_{\text{dis}} = \mathbb{E}_{(z,y,c)}[-\log D(z, y)_c]
$$

编码器损失（通过梯度反转层）：
$$
\mathcal{L}_{\text{adv}} = \mathbb{E}_{(z,y)}[\text{CE}(D(z, y), \text{uniform})]
$$
其中 CE 为交叉熵，uniform 为均匀分布。这迫使 $D$ 无法从 $(z, y)$ 中预测 $c$，即 $p(c \mid z, y) = p(c \mid y)$，从而近似 $I(\Phi(x); c \mid y) = 0$。

#### 3. 总损失函数
$$
\mathcal{L} = \mathcal{L}_{\text{EP}} + \lambda_{\text{orth}} \mathcal{L}_{\text{orth}} + \lambda_{\text{domain}} \mathcal{L}_{\text{domain}} + \lambda_{\text{cont}} \mathcal{L}_{\text{cont}} + \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}
$$
其中：
- $\mathcal{L}_{\text{EP}}$：自适应 IMMAX 损失（主预测损失）。
- $\mathcal{L}_{\text{orth}}$：正交损失（现有）。
- $\mathcal{L}_{\text{domain}}$：无条件域对抗损失（现有，可选保留）。
- $\lambda_{\text{cont}}, \lambda_{\text{adv}}$ 为平衡超参数。

### 核心机制

#### 1. 条件互信息最小化的双重驱动
- **对比学习**：在表示空间强制同类样本聚集，异类样本分离。跨细胞系的同类聚集自然削弱表示与细胞系的关联。
- **条件对抗**：通过博弈迫使表示在给定标签后不再泄露细胞系信息。判别器同时观测标签 $y$，避免将标签相关的细胞系差异误判为泄露。

#### 2. 能量分解的唯一性提升
对比损失约束 $U_I(\Phi(x))$ 在同类样本间相似，不同类样本间差异。由于 $R_E(c)$ 仅依赖细胞系，同类样本的 $U_I$ 相似性迫使 $R_E$ 吸收细胞系特异性偏差，从而减少分解任意性。

#### 3. 优化景观的平滑化
对比损失在表示空间引入 Lipschitz 连续性约束，防止同类样本表示坍缩到离散点，扩大优化吸引子的 basin，增强对分布偏移的鲁棒性。

### 物理/生物对应

- **对比学习**：类比自然选择中保守的顺式调控元件（CRE）在不同细胞类型中保持功能，尽管表观环境变化。
- **条件对抗**：模拟实验科学中的“控制变量”思想：比较相同互作状态（$y$）下不同细胞系的序列特征，分离出细胞系无关的因果信号。
- **能量分解**：$U_I$ 对应序列固有的结合亲和力（由 TF 结合位点决定），$R_E$ 对应细胞系特异的染色质可及性能垒。对比学习确保 $U_I$ 仅反映保守亲和力。

## 架构设计

### 1. 修改点（最小侵入）
- **表示归一化层**：在 $\Phi(x)$ 后添加 L2 归一化（仅用于对比损失）。
- **条件判别器**：小型 MLP，输入为 $z$ 与 $y$ 的 one-hot 拼接，输出 $|\mathcal{C}|$ 维 logits。
- **梯度反转层**：在 $z$ 输入判别器前插入 GRL（系数 $\alpha$）。
- **损失集成**：在现有损失计算模块中添加 $\mathcal{L}_{\text{cont}}$ 与 $\mathcal{L}_{\text{adv}}$。

### 2. 训练流程
```
for each batch (x, y, c):
    z = backbone(x)          # 现有 PRISMBackbone
    z_norm = L2_normalize(z) # 用于对比损失

    # 现有能量头
    U_I = energy_head(z)
    R_E = impedance_table(c)
    prob = sigmoid((U_I - R_E) / T)

    # 计算损失
    loss_ep = adaptive_immax(prob, y)
    loss_orth = ...          # 现有正交损失
    loss_domain = ...        # 现有域对抗损失（可选）
    loss_cont = supcon(z_norm, y)  # 监督对比损失
    loss_adv = conditional_adversarial(z, y, c)  # 条件对抗损失

    total_loss = 加权求和
    total_loss.backward()
```

### 3. 推理流程
**不变**：仅需 $U_I(z)$ 与 $R_E(c)$，与现有流程完全一致。对比与对抗模块仅在训练时激活。

## 理论优势

### 1. 泛化界收紧
设 $\mathcal{H}$ 为假设空间，$\hat{\mathfrak{R}}_n(\mathcal{H})$ 为 Rademacher 复杂度。对比损失引入的同类紧致性约束实际缩小了有效假设空间 $\mathcal{H}_{\text{cont}} \subset \mathcal{H}$，降低 $\hat{\mathfrak{R}}_n(\mathcal{H}_{\text{cont}})$。

### 2. 分布偏移抵抗
条件对抗确保表示满足 $p(c \mid z, y) = p(c \mid y)$，即细胞系分布偏移在给定 $y$ 后不影响表示分布。这降低有效 Wasserstein 距离 $W_1(\mathcal{D}_{\text{train}}, \mathcal{D}_{\text{test}} \mid y)$。

### 3. 信息论最优性
解 $\min I(\Phi(x); c \mid y)$ 是因果表示学习在离散环境下的松弛形式。当 $I(\Phi(x); c \mid y) = 0$ 时，表示 $\Phi(x)$ 只携带 $y$ 的因果信息，过滤掉细胞系特异的虚假路径。

## 实施考量

### 超参数设置
- $\lambda_{\text{cont}}$：初始建议 0.5，随训练线性衰减。
- $\lambda_{\text{adv}}$：初始建议 0.2，保持稳定。
- 对比温度 $\tau$：默认 0.07。
- 判别器学习率：略高于主干（如 5 倍），确保判别器足够强。

### 收敛保障
- 对比损失可能初期主导，可设置 warm-up 阶段逐步增加 $\lambda_{\text{cont}}$。
- 条件对抗需平衡：判别器过强导致训练不稳定，过弱则约束无效。监控判别器准确率，目标接近随机猜测（$1/|\mathcal{C}|$）。

### 兼容性
- 与现有能量耗散框架、自适应 IMMAX 损失、正交损失完全兼容。
- 可选择性保留无条件域对抗损失，但可能冗余。

## 风险缓解

### 1. 数据依赖风险（低）
仅需序列与细胞系标签，无需外部拓扑数据。符合项目数据现状。

### 2. 训练-推理不一致风险（低）
对比与对抗模块仅在训练时激活，推理流程与现有模型完全相同，保证一致性。

### 3. 实现复杂度风险（中等）
需新增约 200 行代码（对比损失、条件判别器、GRL 集成），但模块化设计便于调试。

### 4. 优化稳定性风险（中等）
多损失平衡可能需调参。预案：实施损失权重自适应（如 GradNorm）或分段训练（先预训练对比，后微调全模型）。

## 预期收益

- **主要目标**：将测试 AUPR 从 0.684 提升至 ≥ 0.75。
- **次要目标**：缩小训练-测试泛化差距（当前 0.293），目标 ≤ 0.15。
- **可解释性提升**：$U_I$ 更纯粹反映序列固有亲和力，便于后续生物学分析。

## 验证标准

1. **收敛性**：训练损失平稳下降，无振荡。
2. **判别器平衡**：细胞系分类准确率接近随机水平（~25%，共 8 细胞系）。
3. **表示可视化**：t-SNE 显示同类样本跨细胞系聚集。
4. **最终指标**：domain-kl/test AUPR ≥ 0.75，各细胞系 AUPR 均衡。