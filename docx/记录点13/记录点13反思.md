记录点13反思：自杀式对抗训练的教训

一、核心现象
1. **Pull 损失恒为 0**：
   - 训练日志显示 `pull` 项始终为 0.0000。
   - 这意味着 $L_{S1} \le L_{S2}$ 恒成立，即 Master (S1) 的表现始终优于或等于 Opportunist (S2)。
   - 预期中的“S2 利用捷径快速下降，S1 被迫追赶”的竞争局面从未形成。

2. **S2 表现极差**：
   - S2 (Opportunist) 的 Loss 极高，甚至不如随机猜测。
   - 这导致 S1 即使什么都不学也能轻松击败 S2，因此没有受到任何来自竞争机制的驱动力。

3. **最终过拟合**：
   - 由于缺乏有效的竞争和正则化，S1 最终在训练集上过拟合（AUPR > 0.9），但在测试集上表现惨淡（AUPR < 0.6），甚至不如简单的环境阻抗基线。

二、根因分析
1. **Push Loss 的逻辑谬误 (Suicidal Push)**：
   - 当前代码中，Push Loss 被定义为 `maximize L_{S2}` (当 S1 > S2 时) 或类似的惩罚。
   - 具体实现中，为了“惩罚 S2 的盲目自信”，我们实际上是在优化器中去最大化 S2 的分类损失。
   - 结果：优化器“听话”地摧毁了 S2 的参数，使其变成了只会输出随机噪声的废人。
   - 一个“废人”是无法作为“机会主义者”提供有价值的捷径信息的，因此 S1 失去了竞争对手。

2. **梯度流向的错位 (Gradient Blocking Issue)**：
   - **S1 输入被 Detach**：为了防止 S1 仅仅为了“像 S2”而破坏 Backbone，代码中可能错误地切断了 S1 对 Backbone 的梯度回传（需核查代码确认）。
   - **S2 输入未 Detach**：S2 本应只更新自己的 Head 或特定分支，但如果它对 Backbone 有梯度回传，且我们又在最大化 S2 Loss，那么 Backbone 实际上在被“负向训练”（Unlearning），这极大地破坏了特征提取能力。

3. **竞争机制的死锁**：
   - 由于 S2 被摧毁，$L_{S2}$ 很大。
   - 由于 $L_{S1}$ 正常下降（或维持现状），$L_{S1} \ll L_{S2}$。
   - `Pull = ReLU(L_{S1} - L_{S2})` 恒为 0。
   - 整个系统退化为：S1 独自训练（可能带有错误的梯度流），S2 随机游走。

三、结论
必须立即停止当前的“自杀式”对抗逻辑。
记录点14 的核心任务是**重建健康的竞争关系**：
1. **复活 S2**：S2 必须是一个全力以赴的“优等生”（只是倾向于走捷径），而不是被刻意打压的“差生”。只有 S2 强了，S1 才能更强。
2. **修正梯度**：S2 不应影响 Backbone（Stop Gradient），S1 必须驱动 Backbone。
3. **调整竞争**：Push Loss 应当是“当 S1 已经比 S2 好时，防止 S1 偷懒”，而不是“把 S2 变傻”。或者干脆先移除 Push，只保留 Pull，让 S1 拼命追赶 S2 的捷径性能，同时保持鲁棒性。
