记录点11反思：蒸馏版CED‑Net在实现层面的系统性偏差与模式坍塌

一、现象复盘：从“第二基线”到彻底坍塌

1. 指标对比
- 第二基线（记录点4，环境解耦方法）：
  - GM12878 AUPR≈0.6853，其他细胞系普遍在 0.67–0.72 区间。
  - AUC 在 0.68–0.74 区间，整体排序能力强，虽然存在阈值偏高、置信度上移等问题，但没有发生模式坍塌。
- 记录点7（第一次学生竞争机制）：
  - AUPR 全面下滑，如 GM12878 从 0.6853 降到 0.6364，出现“比第二基线更差”的倒退。
- 记录点8–9（Meta-Learning + 元批次采样）：
  - AUPR≈0.53，Recall=1.0，Precision≈0.5，等价于“几乎全选”。
  - 模型退化为盲目猜测，完全丢失排序结构。
- 记录点10（CED‑Net 架构调优）：
  - AUPR 稍有抬头（0.56–0.59），但 F1 极低，依然处于“半崩溃”状态。
- 记录点11（当前）：
  - AUPR≈0.51–0.53，AUC≈0.51–0.53，F1 普遍在 0.18–0.29 之间。
  - 指标已经接近“完全随机 + 轻微偏置”的水平，说明模型不仅没超越第二基线，连普通 cross attn 都远远不如。

2. 训练与预测的异像
- 训练日志（记录点11训练日志）：
  - 训练集 AUPR 在 0.85–0.92 区间，AUC 也在 0.86–0.88，损失单调下降，看起来“非常健康”。
  - Domain Loss 随 Epoch 稳定下降，说明 GRL 正在有效压制细胞系信息。
- 测试结果（历史结果.log 中记录点11）：
  - 所有细胞系的 AUPR、AUC 都接近 0.5，F1 极低。
  - 阈值选择后，仍然无法恢复任何有意义的 Precision/Recall 结构。

这说明：训练过程本身没有明显数值问题，梯度也在正常流动；真正的问题在于训练目标和推理流程之间的逻辑断裂，以及蒸馏竞争机制与能量耗散系统的耦合方式出现了根本性偏差。


二、核心思想回顾：本来想解决什么问题

1. 解耦对抗算子的原始数学目标
- 通过 Backbone 生成纯粹的内势 U_I，仅依赖序列本身，代表“在真空中的互作倾向”，跨细胞系不变。
- 通过旁路或蒸馏模块生成环境阻抗 R_E，代表当前细胞系的负载或抑制，使得：
  - P(y=1) = σ((U_I − R_E) / T)
  - 未见细胞系时，只要 U_I 正确，R_E 的估计哪怕有偏，排序依然由 U_I 主导，模型天然具备鲁棒性。

2. 学生竞争机制的补充目标
- Teacher 拥有 Cell ID 和全局原型图，能在“上帝流形”上给出理想的环境阻抗分布。
- Student1 必须仅凭 EP 分布（支持集）重建出 Teacher 的环境阻抗，从而摆脱对 Cell ID 的直接依赖。
- Student2 则故意走捷径，逼迫 Student1 通过 Push‑away 拆掉那些“看起来有用但对 OOD 有害”的投机特征。

3. 预测端的理想图景
- 已知细胞系：可以直接使用 Teacher 或 Cell Embedding 提供的 R_E，或者融合 Student 的估计，进行环境纠偏。
- 未知细胞系：只要给出一小撮该细胞系的 EP 样本，Student 就能根据 U_I 分布与样本标签，推断出一组合理的 R_E，从而实现 OOD 纠偏。


三、当前实现的关键偏差：训练看似“很强”，推理却在“瞎猜”

1. U_I 与 R_E 的实现位置是对的，但使用方式是错的
- PRISMBackbone.forward 中已经实现：
  - U_I = FourierEnergyKAN(z_I)，由 Anchor 表征聚合得到 z_I。
  - z_G, z_F = BypassDecoupler(z_I)，再由 resistance_generator(z_F) 得到 R_E≥0。
  - 最终概率 prob = σ((U_I − R_E)/T)，形式上是正确的能量耗散模型。
- 问题出在：
  - 训练时，R_E 同时被用作正则（稀疏 L1）、蒸馏对齐的载体以及 CED‑Net 中 Student 推断 R_S 的中间量，目标过于复杂且互相掺杂。
  - 推理时，在 OOD 场景（predict.py 中 cell_labels=None）下，backbone 仍然会通过 bypass_generator 和 resistance_generator 生成一个 R_E，但这个 R_E 没有任何来自“当前细胞系上下文”的约束，仅仅是 z_I 的一个非线性投影，和真实环境阻抗几乎没有可解释关系。

结果：模型在训练时把大量能力用在“如何用 R_E 拉低或抬高 U_I 让 loss 好看”，而不是学习一个可以泛化的环境因子；推理时却指望这个 R_E 能纠偏真实细胞系环境，这是逻辑上的错位。

2. 蒸馏学生模块“学的是原型分布”，但主预测不真正用它
- 在 PRISMModel.forward 中：
  - 当 DISTILL_ENABLED 为真且 training 为真时，才会调用 teacher 和 student1、student2。
  - teacher(cell_labels) 得到 target_dist、R_T、R_protos、M_T。
  - student1、student2 接收 (z_I, z_F)，输出原型分布 logits。
  - compute_loss 中通过 ced_net_losses 和 compute_competition_loss 对这些分布施加 KL 以及 Pull‑in/Push‑away。
- 但主预测 prob 的定义始终固定为：
  - E_total = U_I − R_E
  - prob = σ(E_total / T)

也就是说：
- 训练时，Student 在一个“侧任务世界”里和 Teacher、Student2 激烈博弈；
- 推理时，真正上场的是另一套 R_E（由 z_F→resistance_generator），Student 的成果没有进入主能量公式。

3. PRISM.py 与 predict.py 的语义严重不一致
- 训练端 PRISM.py：
  - 使用 MetaBatchSampler，在每个元批次中混合多个细胞系的 Block，让 CED‑Net 通过 ρ、pull 和 push 拆捷径。
  - 训练 AUPR 在 0.9 左右，说明在训练分布上，U_I 加上这个被大量正则和对抗约束的 R_E 能拟合训练标签。
- 预测端 predict.py：
  - 使用 CellBatchSampler，保证每个 batch 是单一细胞系，做的是“按细胞系切片后重新评估”的 OOD 风格评估。
  - 主路径调用 backbone(e, p, cell_labels=None)，触发的是“无标签分支”，即只依赖 z_I 通过 bypass_generator 生成的 z_F 再生成一个 R_E。
  - 可选 Student 分支仅在 inference 阶段被临时调用几行代码。

训练优化的目标和预测时真正被使用的路径并不对齐，这是模式坍塌的核心机制之一。


四、模式坍塌的具体机制：为何输出全部挤到 0.5 附近

1. 公平竞争机制在实现层面几乎“空转”
- 训练日志中，APL 的 ρ 长期稳定在 1.0 左右，push 与 pull 在大部分 step 上接近 0，这与“Epoch 9/25 仍然 push=0, pull=0”的现象完全一致。
- 这暴露出两个实现层面的关键问题：
  - compute_competition_loss 以整 Batch 平均 BCE 作为 loss_s1、loss_s2，APL 只能看到一个“全局平均谁略好一点”，而看不到“在哪个细胞系、哪类样本上谁更好”；
  - APL 的更新完全在混合 Meta‑Batch 上进行，从未在“按细胞系划分的 episodic 任务”上单独度量 Student 与 Opportunist 的胜负。
- 结果就是：在训练过程中，系统几乎从未进入“强制拉 Student 一把”或者“强行压制 Opportunist”的状态。所谓的公平竞争退化为恒定权重的附加项，CED‑Net 看起来存在，但实际上没有改变任何样本级或细胞系级的学习节奏。

2. U_I 被卷入蒸馏博弈，失去了作为“硬核排序引擎”的角色
- 理论上 U_I 应该被保护成“只看序列”的内势，不参与蒸馏博弈的扭曲。
- 记录点11的实现中，z_I 同时承担：
  - 能量头 U_I 的输入；
  - BypassDecoupler 的输入（生成 z_G、z_F）；
  - CED‑Net 内部正交损失、KL 蒸馏和竞争损失的公共入口。
- Push‑away 及 KL 对齐误差的梯度通过 compute_loss 直接回流到 Backbone，使得“为了让 Student2 输一点”、“为了贴近 Teacher 的分布”，优化器会去重塑 z_I 本身。
- 当 Opportunist 在某些细胞系上学到非常投机但对训练集 loss 有利的模式时，Push‑away 并不是只切断 R_E 相关的通路，而是在整体上扭曲 z_I，最终让 U_I 的排序能力也被共同牺牲，输出自然滑向一个安全但无信息量的常数区间。

3. Student 训练和推理面对的是两套完全不同的任务分布
- 训练阶段：
  - 使用 Meta‑Batch 在一个 Batch 内混合多个细胞系的 Block，Student 与 Opportunist 在“跨细胞系混合任务”上分高下；
  - APL 的 ρ 统计的也是这种混合分布上的 EMA 比值。
- 推理阶段：
  - 使用 CellBatchSampler，一次只看一个细胞系，希望 Student 能在“单细胞系 episodic 任务”上从 Support Set 估计出 R_E(c)，再在该细胞系全局上提升 AUPR。
- 训练和推理的任务形态完全不同：APL 从未在真正需要 Student 发力的 per‑cell Task 上被校准，Student 也从未在“按细胞系切片后统一使用 (U_I − R_E(c))/T”的场景下被优化。
- 因此，“公平竞争机制”在日志上是存在的，但在真实评估路径上几乎不起作用：它既没有在合适的任务上拉开 Student 与 Opportunist 的能力差距，也没有让任何一个细胞系的 R_E 被学习得更好，最终只能让整个系统退回到“所有人都选择输出一个安全常数”的平凡解。


五、总体结论：不是思想错了，而是训练与推理没有忠实执行思想

1. 记录点4的能量耗散与解耦对抗思想是正确的
- U_I 与 R_E 的分工在数学上非常清晰；
- 只要 U_I 被保护好，R_E 只做温和调节，AUPR 不应比第二基线差。

2. 学生竞争机制本身也不是问题根源
- CED‑Net 的设计初衷是让 Student 从分布中学习环境阻抗图；
- 问题出在把过多复杂约束堆叠在同一个训练目标上，并让 U_I 被这些约束牵着走。

3. 真正的病灶在于训练优化的目标与推理时的真实任务不一致
- 训练在混合细胞系的 Meta‑Batch 上最小化一堆损失；
- 推理在按细胞系 episodic 的 OOD 任务上评估 AUPR；
- 中间缺少一个“桥梁”，即在训练时就对齐推理端的任务形式和能量公式。


六、针对记录点11的定位：为什么在已有坍塌基础上进一步恶化

在记录点8–10 的基础上，记录点11主要做了两件事：
- 更彻底地把 CED‑Net、解耦对抗和能量耗散全部嵌进 PRISMBackbone；
- 在 predict.py 中尝试引入 Student 推理和 per‑cell 分支选择。

结果是：
- 模型参数空间过度耦合，任何一个子模块的不稳定都会影响整体；
- 训练和推理依然没有在同一个任务上对齐，再复杂的推理逻辑也无法补偿训练目标的偏差。


七、下一步修复方向的锚点（为记录点12方案做铺垫）

1. 重新简化能量模型
- 明确保护 U_I，使其从蒸馏和竞争逻辑中抽离出来，只承担序列互作排序；
- 将 R_E 的职责压缩到“仅做环境纠偏”，不再承担多重对齐与流形任务。

2. 训练和推理的任务形式必须统一
- 训练时就以“按细胞系 episodic 采样 + Support Set 估计 R_E + (U_I − R_E)/T 预测”的形式进行；
- 推理时复用完全相同的数据流，仅将 Support Set 换为测试集自身的无标签或少标签样本。

3. Student 的 R_S 必须进入主预测路径
- 不再把 Student 作为 loss 的辅助源，而是将其输出的 R_S 明确作为环境阻抗；
- 对已知细胞系可融合 Teacher 的 R_T，对未知细胞系则完全依赖 R_S。

4. 适度削减 CED‑Net 的复杂度
- 保留 Teacher 原型图、Student 分布推断和 Push‑away 拆捷径；
- 删除或弱化与当前目标关联不强的流形对齐和多重正则，将系统收缩到一条清晰可解释的数据流。

记录点11的价值在于，它让问题暴露得足够彻底：当训练与推理不在同一个问题上时，再漂亮的数学方案也只能把模型推向“所有人都不太用力、输出一个安全常数”的平凡解。记录点12必须从重新对齐训练与推理的任务开始，重建 U_I、R_E 与 Student 各自的角色。
