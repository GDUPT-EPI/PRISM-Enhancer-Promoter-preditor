# 记录点24 反思

## 失败结构定理

**记录点24失败的核心在于：扩展的能量耗散框架 $U_I - R_E + \lambda U_I R_E$ 引入了高阶交互自由度，但缺乏足够的结构先验来约束这些自由度的学习方向，导致模型利用交互项记忆训练集细胞系特异性噪声，而非学习跨细胞系不变的调节机制。**

数学上，设真实数据生成过程为：
\[
y = f_{\text{true}}(x, c) + \epsilon
\]
其中 $f_{\text{true}}$ 可分解为不变部分 $f_I(x)$ 与环境调节部分 $g(x, c)$。模型假设：
\[
\hat{f}(x, c) = \sigma\left(\frac{U_I(x) - R_E(c) + \lambda U_I(x) R_E(c)}{T}\right)
\]
当 $\lambda$ 可自由学习时，模型有无限多组解 $(U_I, R_E, \lambda)$ 可以完美拟合训练数据，其中绝大多数对应着**过参数化的特解**：$U_I$ 记忆序列噪声，$R_E$ 记忆细胞系ID，$\lambda$ 调节两者协同来拟合标签。这些特解在测试集上泛化失败，因为测试细胞系的环境阻抗 $R_E(c')$ 无法从训练集中外推。

## 根因分析

### 数学层面

#### 1. 优化景观的病态性
损失函数 $\mathcal{L} = \mathcal{L}_{\text{task}} + \alpha\mathcal{L}_{\text{corr}} + \beta\mathcal{L}_{\text{inv}} + \gamma\mathcal{L}_{\text{hcont}} + \delta\mathcal{L}_{\text{sparse}}$ 存在**多重局部最优**，其中许多对应平凡解：

- **高Recall解**：设 $U_I \approx \text{常数} > 0$，$R_E \approx 0$，$\lambda \approx 0$，则 $P(y=1) \approx \sigma(\text{常数}/T) \approx 0.9$，Recall ≈ 1.0，Precision ≈ 0.5（与NHEK、Ovary观察一致）。
- **过拟合解**：$U_I(x)$ 学习训练集序列特异性模式，$R_E(c)$ 学习细胞系查表，$\lambda$ 微小调节，在训练集上 AUPR > 0.96，测试集泛化差。

相关性约束 $\mathcal{L}_{\text{corr}}$ 只要求 $z_I$ 与 $z_E$ 线性无关，但允许 $z_I$ 包含细胞系信息（只要与 $z_E$ 不相关）。域对抗 $\mathcal{L}_{\text{inv}}$ 理论上应去除 $z_I$ 中细胞系信息，但GRL训练不稳定，容易失效。

#### 2. 表示几何的坍缩
训练AUPR 0.9653 表明表示空间 $z_I$ 与 $z_E$ 的联合分布对训练标签高度可分。但测试AUPR 0.6937 表明这种可分性主要依赖**条件独立性的违反**：$P(z_I, z_E | y, c_{\text{train}}) \neq P(z_I, z_E | y, c_{\text{test}})$。

几何上，$z_I$ 与 $z_E$ 可能在训练细胞系的子流形上形成复杂决策边界，但该边界无法泛化到新细胞系。分层对比学习虽然强化了同一细胞系内样本的聚集，但未能强制**跨细胞系的流形对齐**。

#### 3. 泛化理论视角
模型复杂度由三部分贡献：
1. 基模型容量（PRISMBackbone）：~1300万参数，VC维高。
2. 交互项引入的乘积特征 $U_I R_E$：将假设空间从线性函数扩展到二次函数。
3. 稀疏性正则 $\delta=0.01$ 相对主损失太小，不足以有效约束。

Rademacher复杂度上界：
\[
\mathcal{R}_n(\mathcal{H}) \geq \mathcal{R}_n(\mathcal{H}_{\text{linear}}) + \lambda_{\text{interaction}} \mathcal{R}_n(\mathcal{H}_{\text{quadratic}})
\]
交互项显著增加了复杂度，而训练样本数 $n=145,534$ 不足以约束此增长，导致泛化差距 $|L_{\text{train}} - L_{\text{test}}|$ 扩大。

#### 4. 信息论瓶颈
目标为最小化 $I(z_I; c)$（不变性）同时最大化 $I(z_I; y|c)$（预测性）。实践中，域对抗损失试图最小化 $I(z_I; c)$，但交互项 $U_I R_E$ 在解码端重新引入了 $z_I$ 与 $c$（通过 $R_E$）的依赖，形成**信息泄漏**：细胞系信息可通过 $R_E$ 影响预测，绕过了对 $z_I$ 的不变性约束。

### 算法层面

#### 1. 交互项实现缺陷
代码中交互项为 $\lambda U_I R_E$，其中 $U_I = g_I(z_I)$，$R_E = g_E(z_E)$。但 $g_I$ 与 $g_E$ 均为MLP，可将任意信息编码到标量 $U_I$ 与 $R_E$ 中。模型可学习让 $U_I$ 编码细胞系信息，$R_E$ 编码序列信息，然后通过 $\lambda$ 调节符号，从而完全颠覆解耦意图。缺乏对 $U_I$ 与 $R_E$ 的语义约束。

#### 2. 相关性损失的局限性
Pearson相关系数只捕捉线性相关性。$z_I$ 与 $z_E$ 可在非线性相关下仍保持 $\text{Corr} \approx 0$。例如，设 $z_E = \sin(z_I)$，则相关系数为0但完全依赖。需要更严格的独立性度量如HSIC或互信息估计。

#### 3. 温度学习失效
日志显示温度 $T$ 可能未有效学习（固定为1.0），或学习到极端值导致Sigmoid饱和。当 $T \to 0$，$P(y=1) \to \mathbb{1}_{U_I - R_E + \lambda U_I R_E > 0}$，决策边界硬化，对能量估计误差敏感。

#### 4. 批次采样纯度不足
虽然使用 `CellBatchSampler`，但批次大小64可能仍包含序列异质性，使得 $z_E$ 估计为批次平均，丢失细胞系内变异信息。更严重的是，训练集细胞系（ALL, CD34, HeLa, K562, Liver, Thyroid）与测试集细胞系（GM12878, NHEK等）完全不同，$z_E$ 的估计器无法泛化。

### 生物学层面

#### 1. 非线性交互的生物学误用
假设 $U_I R_E$ 表示环境对序列效应的调节，但生物学中这种调节通常是**阈值化**或**饱和**的，而非线性乘积。例如，染色质开放区域可能允许转录因子结合（$R_E$ 低时 $U_I$ 有效），但染色质封闭时完全阻断（$R_E$ 高时 $U_I$ 无效）。乘积模型允许部分阻断，可能不符合生物学现实。

#### 2. 解耦目标与发育生物学冲突
试图完全分离 $z_I$（序列）与 $z_E$（环境）忽略了两者在发育中的**共进化**。保守序列模块往往在特定染色质环境中发挥功能。强行解耦可能丢弃功能相关的协同特征。

#### 3. 稀疏性假设过于简化
L1稀疏假设只有少数特征相关，但基因调控常涉及**组合编码**：多个转录因子微弱信号的叠加产生特异性。稀疏性可能迫使模型选择主导特征，丢失弱但一致的组合信号。

## 关键洞察

### 1. 交互项需要结构性先验
自由学习的交互系数 $\lambda$ 容易过拟合。应施加生物学先验：
- $\lambda$ 的符号约束（协同 vs 拮抗）
- 交互的阈值化（Hill函数而非线性）
- 细胞系类型特定的交互模式

### 2. 解耦需要更强的独立性度量
Pearson相关系数不足。应使用：
- 互信息估计（如MINE）
- 希尔伯特-施密特独立性准则（HSIC）
- 对抗性独立性测试

### 3. 环境阻抗需要可外推的表示
当前 $z_E$ 为细胞系ID的查表式表示。应建模为可观测细胞系特征的函数（如染色质可及性、TF表达），使未知细胞系的 $z_E$ 可通过其特征插值得到。

### 4. 泛化差距的根本是任务错配
训练任务是**批次内细胞系纯化下的表示学习**，测试任务是**跨细胞系排序**。两者目标函数不同：前者优化分类准确率，后者优化AUPR（排序）。应直接在训练中优化排序敏感的损失（如 pairwise ranking loss）。

### 5. 温度应作为正则化工具而非自由参数
温度 $T$ 控制预测熵。应将其与模型置信度校准关联，作为防止过拟合的正则化：高熵（高 $T$）鼓励保守预测，低熵（低 $T$）允许自信预测。可设计熵正则化 $\mathcal{L}_{\text{entropy}} = -T \cdot H(P(y|x,c))$。

## 对下一步的启示

### 必须避免的陷阱
1. **避免无约束的交互项**：交互结构应有生物学先验或稀疏约束。
2. **避免弱独立性约束**：解耦需要统计独立性，而非仅仅线性不相关。
3. **避免ID式的环境表示**：环境应建模为连续特征，支持插值外推。
4. **避免分类损失主导**：引入排序优化目标直接提升AUPR。

### 应探索的方向
1. **结构化交互模型**：如 $U_I \cdot \sigma(R_E)$（阈值调节）或 $U_I / (1 + R_E)$（抑制饱和）。
2. **基于互信息的解耦**：直接最小化 $I(z_I; z_E)$ 的估计值。
3. **元学习环境表示**：将 $z_E$ 学习为细胞系特征嵌入，而非ID嵌入。
4. **排序感知训练**：在损失中整合AUPR的可微代理（如 pairwise logistic loss）。
5. **多任务架构**：联合预测EP互作与染色质特征，共享底层序列表示。

### 数学重构原则
新方案应从**充分统计量**角度重新形式化问题：寻找最小充分统计量 $T(x,c)$，使得 $P(y|x,c) = P(y|T(x,c))$，且 $T$ 可分解为 $T_I(x)$（不变）与 $T_E(c)$（环境），两者通过结构化函数 $h(T_I, T_E)$ 组合。函数 $h$ 的选择应基于生物学机制假设，而非通用近似。

---

**记录点24的失败揭示：单纯增加模型表达能力（非线性交互）而不施加正确的归纳偏置，只会让模型更高效地过拟合。真正的突破需要将生物学机制转化为数学结构，约束假设空间到与泛化兼容的子集。**

