# CBAT 记录点6反思：GRL的悖论与环境的缺失
# (Reflection Point 6: The GRL Paradox & The Missing Environment)

## 1. 成功经验分析 (记录点4/6)

### 1.1 为什么比 Baseline 和记录点2/3 好？
记录点4和6的核心在于**物理/环境解耦 (Physics-Environment Decoupling)**。
- **Baseline/Record 2**: 试图在一个黑盒模型中同时学习“序列匹配规则”和“细胞特异性规则”。这导致模型在未见细胞系上容易过拟合到训练集的特定环境模式。
- **Record 4/6**: 强制分离了 **$U_I$ (内势)** 和 **$R_E$ (阻抗)**。
    - $U_I$ 通过 GRL 被清洗为纯粹的序列物理化学势能（SOTA级别的潜力）。
    - 这种分离保证了即使环境估计错误，底层的 $U_I$ 依然能提供一个高质量的 Baseline Ranking。这就是为什么 AUPR 能稳定在 0.70 左右，而不会像 Record 3 那样崩溃。

### 1.2 证明了什么假设？
证明了 `解耦对抗算子.md` 中的核心假设：**EP互作 = 序列潜力 - 环境阻抗**。
只要 $U_I$ 足够强（由双向 CBAT + Anchors 保证），模型就有很好的下限。

## 2. 训练集 Accuracy 0.5 之谜

### 2.1 现象
训练集 Log 显示 Acc 趋近 0.5 (随机)，但 AUPR/AUC 表现尚可。

### 2.2 原因：Logit 漂移与阈值失配
- **Logit Shift**: 能量模型输出 $logits = (U_I - R_E) / T$。如果 $U_I$ 和 $R_E$ 的量级未对齐（例如 $U_I \gg R_E$），所有 logits 可能都大于 0（预测全 1），或者反之。
- **Ranking vs Calibration**:
    - **AUPR/AUC** 是排序指标，只关心相对大小。即使所有 logits 都漂移了，只要正样本的 logits 比负样本大，AUPR 就很高。
    - **Accuracy** 是阈值指标（默认阈值 0.5）。如果 logits 整体漂移，Accuracy 就会变成类平衡比例（通常是 50%）。
- **结论**: 模型学会了很好的排序（Ranking），但完全没有学会校准（Calibration）。这是“能量系统”未加约束的常见副作用。

## 3. 致命瓶颈：GRL 的悖论与 OOD 坍缩

### 3.1 当前架构的瓶颈
当前架构 `PRISMModel.py` 在未见细胞系（OOD）上存在一个**逻辑死锁**：

1.  **GRL 的作用**：强迫 $U_I$ **不包含** 细胞系信息。即对于同一对 E-P，无论在哪个细胞系，$U_I$ 都是常数。
2.  **$R_E$ 的依赖**：$R_E$ 依赖于 `cell_embedding`。
3.  **OOD 的困境**：
    - 在未见细胞系上，我们没有训练好的 `cell_embedding`。
    - 通常做法是使用平均 Embedding 或随机 Embedding。
    - 结果：$R_E$ 退化为一个常数（或仅依赖序列的平均阻抗）。
4.  **最终推断**：
    $$ P(y=1 | x, c_{new}) \approx \sigma(U_I(x) - \bar{R}(x)) $$
    这变成了一个**单任务模型**（Single-Task Model），即预测“平均细胞系中的互作”。

### 3.2 为什么 AUPR 卡在 70？
因为**生物学真理是动态的**。
- 真实的 Ranking 在不同细胞系间是**剧烈变化**的（Cell Specificity）。
- 我们的模型预测了一个**静态**的 Ranking ($U_I$)。
- 70% 的 AUPR 代表了所有细胞系共有的“公共互作”（Housekeeping interactions）或强序列偏好，但模型丢失了那 30% 的“特异性互作”（Cell-specific interactions）。

**结论**：只要我们无法在 OOD 上动态获得正确的 `cell_embedding`（即 $R_E$），模型就永远无法突破 70% 的天花板。

## 4. 数学反思：从静态查表到动态重构

我们需要的不是一个静态的 Lookup Table (`nn.Embedding`)，而是一个动态的函数映射：

**当前错误模型**：
$$ R_E = f(Sequence, \text{LookUp}(CellID)) $$

**理想模型**：
$$ R_E = f(Sequence, \text{Context}(Distribution)) $$

其中 $\text{Context}(Distribution)$ 是从当前细胞系的**观测数据**（Sparse Context）中推断出来的。

- **稀疏上下文 (Sparse Context)**：在预测一个新的细胞系时，我们通常会有一些先验信息（例如：已知的几个 Marker Gene 的状态，或者输入的序列分布特征，或者通过 TTA 获得的预测分布）。
- **重构推断 (Reconstructive Inference)**：我们需要在测试阶段，通过优化一个潜变量 $z_{env}$，使得模型的预测分布符合生物学先验（如稀疏性、连通性），从而“重构”出当前的环境阻抗。

## 5. 战略调整：面向分布的上下文建模

为了让 CBAT 在未见细胞系上具备特异性，必须引入**测试时适应 (Test-Time Adaptation, TTA)** 或 **上下文学习 (In-Context Learning)** 机制。

**新策略**：
1.  **Context Placeholder**: 在模型中预留“环境上下文向量”输入，而非固定的 Embedding。
2.  **Distribution Matching**: 在推理阶段，利用 Batch 数据的统计特性（分布）来反推环境向量。
3.  **Entropy Minimization**: 物理世界是确定的（要么结合要么不结合）。通过最小化预测熵，寻找最符合当前数据的环境参数。

---
**痛定思痛**：我们之前的模型是“瞎子背书”（背诵了训练集的细胞ID），现在的目标是让模型变成“侦探”（根据现场线索推断环境）。
