# CBAT 修复方案 (记录点7)：基于 CED-Net 与 ISAB 的进化式上下文蒸馏
# (Solution Point 7: Evolutionary Context Distillation via CED-Net & ISAB)

## 1. 核心反思与战略升级

### 1.1 之前方案的缺陷
- **“先训练后微调”的不确定性**：原方案寄希望于在预测时通过 TTA 无监督地“猜”出环境参数。这在生物学上是不靠谱的，因为缺乏Ground Truth的约束，熵最小化可能导致模型坍缩到错误的自信状态。
- **完全抛弃 Cell ID 的代价**：Cell ID 包含了宝贵的先验信息（Ground Truth）。完全放弃它会导致训练变得极度困难，且浪费了已有的标签数据。
- **OOD 的本质**：OOD 问题不是“无知”，而是“迁移失效”。我们需要一种机制，能将训练集中“数据分布 $\to$ 细胞特异性参数”的映射规则，迁移到未见过的细胞系上。

### 1.2 新战略：进化式上下文蒸馏 (Evolutionary Context Distillation)
我们融合 **CED-Net (Co-Evolutionary Dual-Stream Network)** 的竞争机制与 **ISAB (Induced Set Attention Block)** 的上下文感知能力，构建一个“三位一体”的动态系统：

- **Teacher (稳压器)**:
    - **角色**: 拥有 **Cell ID** 的上帝视角。
    - **作用**: 生成最完美的细胞特异性阻抗 $R_{GT}$，作为 Student 的学习目标。
    - **更新**: 通过 Student 的 EMA (Exponential Moving Average) 更新，不直接参与梯度下降。

- **Student (集大成者)**:
    - **角色**: 只能看 **数据上下文 (Context)** 的凡人。
    - **核心组件**: **ISAB**。它必须通过观察当前 Batch 的分布特征，推断出与 Teacher 一致的阻抗 $R_{Pred}$。
    - **任务**: 既要准确预测互作，又要模仿 Teacher 的阻抗，还要在竞争中压制 Opportunist。

- **Opportunist (机会主义者/S2)**:
    - **角色**: 同样只能看数据，但极其贪婪，专门寻找捷径（Shortcut）。
    - **作用**: 作为 Student 的“磨刀石”。如果 Opportunist 利用某个简单特征（如 GC 含量）就能猜对，说明 Student 的物理建模还不够深刻。Student 必须通过 **Push-away Loss** 主动拆解这些捷径。

## 2. 架构设计

### 2.1 模块一：上下文聚合器 (ISAB Context Aggregator)
为了解决“上下文采样既要多又要处理关系”的难题，我们重启 `models/layers/ISAB.py` 中的 **ISAB (Induced Set Attention Block)**。

- **输入**: 当前 Batch 的 $z_I$ (Intrinsic Features)，形状 `[B, D]`。
- **Inducing Points**: 学习 $M$ 个可学习的“环境原型” (Inducing Points)，代表通用的环境特征基。
- **机制**:
    1.  $I \to X$: 环境原型查询当前 Batch 的数据，提取统计特征。
    2.  $X \to I$: 数据反向聚合信息，形成紧凑的上下文向量 $C_{batch}$。
- **优势**: $O(M \cdot B)$ 复杂度，允许我们在训练时使用超大 Batch (如 1024) 进行上下文采样。

### 2.2 模块二：CED-Net 三路阻抗生成

$$
\begin{aligned}
\text{Teacher: } & R_{T} = \text{ResNet}(\text{Embedding}(\text{CellID})) \\
\text{Student: } & R_{S} = \text{ResNet}(\text{ISAB}(\text{BatchFeatures})) \\
\text{Opportunist: } & R_{O} = \text{MLP}(\text{SimpleStats}(\text{BatchFeatures}))
\end{aligned}
$$

### 2.3 模块三：LoRA 的适用性分析 (关于 LoRA 的思考)
用户提问：**LoRA 对这个任务是否有帮助？**

**分析结论：有帮助，但需谨慎使用。**
- **帮助点**: OOD 适应本质上是 Domain Adaptation。LoRA 非常适合作为 **Test-Time Adaptation (TTA)** 的轻量级参数。当 Student 进入一个新的细胞系时，我们可以冻结主干，仅微调 LoRA 参数来快速适应新环境的 $R_E$ 分布，而不会破坏已学到的 $U_I$ 物理规律。
- **风险点**: 如果在预训练阶段就大量使用 LoRA，可能会限制模型对底层复杂特征的提取能力。
- **决策**: **Training 阶段不用 LoRA** (全参数训练以获得最强 Backbone)；**Inference 阶段 (TTA) 可选 LoRA** (作为快速适应接口)。但在本方案中，我们优先依赖 ISAB 的 Zero-shot 推断能力，LoRA 作为备选 TTA 策略。

## 3. 训练策略 (The Training Recipe)

### 3.1 损失函数体系 (基于 IMMAX)

$$ L_{total} = L_{S} + L_{O} + L_{distill} + L_{compete} $$

1.  **Student Task Loss**: $L_{S} = \text{IMMAX}(\hat{y}_S, y)$
2.  **Distillation Loss (Crucial Update)**: 
    我们采用蒸馏学习不仅仅是为了模仿 Teacher 的输出，而是为了**使得模型对于 OOD 细胞系可以真正的学会从 EP 分布中推断 EP 特异性信息**，从而准确地对 EP 互作进行纠偏。
    $$ L_{distill} = \| R_{S}(SupportSet) - R_{T}(CellID) \|_2^2 $$
    Student 必须学会：观察这一组 $(E, P)$ 的分布（Support Set），推断出 Teacher 看到的那个 $R_{T}$。
    这避免了 Student 退化为一个保守的平凡解（如记录点4），赋予其真正的动态适应能力。
3.  **Opportunist Task Loss**: $L_{O} = \text{IMMAX}(\hat{y}_O, y)$
2.  **Opportunist Task Loss**: $L_{O} = \text{IMMAX}(\hat{y}_O, y)$
3.  **Distillation Loss**: $L_{distill} = ||R_S - \text{StopGrad}(R_T)||^2$ (Student 必须像 Teacher 一样思考)
4.  **Competition Loss (Pull-in & Push-away)**:
    - **Pull-in**: 当 $Loss_S > Loss_O$ 时，惩罚 Student (你居然输给了投机取巧者？)。
    - **Push-away**: 当 $Loss_S \ll Loss_O$ 时，反向更新 Backbone，使得 Opportunist 的捷径失效 (拆掉过拟合特征)。

### 3.2 APL 自适应步调锁 (Adaptive Pacing Lock)
为了防止 Student 或 Opportunist 一方独大，我们引入 APL：
- 定义性能比 $\rho = \text{EMA}(L_S) / \text{EMA}(L_O)$。
- **$\rho \ll 1$ (Student 落后)**: 抑制 Opportunist 更新，给 Student 喘息机会。
- **$\rho \approx 1$ (胶着)**: 正常竞争。
- **$\rho > 1$ (Student 领先)**: 加大 Opportunist 更新力度，或让 Student 主动通过 Push-away 拆解捷径。

### 3.3 采样策略
- **Context Sampling**: 训练时，从同一细胞系的数据池中随机采样 $N=1024$ 个样本作为“背景板”输入 ISAB。
- **Warmup**: 前 5 步仅进行 Teacher-Student 蒸馏，不开启竞争，让 Student 先学会基本功。

## 4. 代码修改清单

### 4.1 `models/PRISMModel.py`
- **引入 ISAB**: 实例化 `ISAB` 作为 Student 的 Context Encoder。
- **实现 CED-Net 结构**:
    - `forward_teacher`: 使用 Cell ID。
    - `forward_student`: 使用 ISAB Context。
    - `forward_opportunist`: 使用简单统计特征 (或独立的轻量网络)。
- **LoRA 接口**: 预留 LoRA 注入点，以便未来 TTA 扩展。

### 4.2 `PRISM.py` (训练循环)
- **实现 CED-Net 训练流**:
    1.  Teacher EMA 更新。
    2.  Student/Opportunist 前向。
    3.  计算 IMMAX Loss, Distillation Loss, Competition Loss。
    4.  计算 APL 因子。
    5.  反向传播 (注意 Push-away 的梯度屏蔽)。

---

**总结**：这是 CBAT 的进化版。它不再是一个静态的预测器，而是一个动态的进化系统。Teacher 指引方向，ISAB 赋予环境感知能力，Opportunist 负责磨砺鲁棒性。三者协作，确保模型在 OOD 细胞系上既能“看懂环境”，又“不走捷径”。
