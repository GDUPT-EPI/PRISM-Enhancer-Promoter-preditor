# 记录点28 方案：可验证对齐特征调制网络 (Verifiably Aligned Feature Modulation Network, VAFMN)

## 核心洞察（一句话）

**细胞系特异性调节的本质是稀疏特征选择，但必须通过可验证的架构对齐、信息瓶颈驱动的解耦、以及渐进式硬约束注入来实现，确保方案与实施零断层，从而获得可泛化、可解释的细胞系不变性。**

## 问题的数学形式化

### 输入与输出空间（同记录点27）
- 输入序列对：$x = (E, P) \in \mathcal{X} \subset \mathbb{V}^{L_E} \times \mathbb{V}^{L_P}$
- 细胞系标签：$c \in \mathcal{C}$，连续表观特征 $v_c \in \mathbb{R}^m$（可学习）
- 标签：$y \in \{0,1\}$ 表示EP互作
- 观测分布：$(x,c,y) \sim P_{\text{data}}$，$\mathcal{C}_{\text{train}} \cap \mathcal{C}_{\text{test}} = \emptyset$

### 记录点27失败的数学诊断
1. **断层导致的约束失效**：设计空间 $\mathcal{S} = \{f_{\theta}(x,c) = \sigma(\langle w, \phi(x) \odot g_{\psi}(c) \rangle)\}$，实现空间 $\mathcal{I} = \{f'_{\theta}(x,c) = \sigma((U_I(\phi(x)) - R_E(c))/T)\}$，$\mathcal{S} \cap \mathcal{I} = \emptyset$。

2. **平移对称性导致的过拟合**：能量分解 $U_I - R_E$ 的对称群 $G = \{(U_I, R_E) \mapsto (U_I + \alpha, R_E + \alpha) | \alpha \in \mathbb{R}\}$ 引入冗余自由度，VC维增加 $\dim(G) = 1$。

3. **软约束的梯度淹没**：$\mathcal{L}_{\text{align}}$ 权重 $\alpha=1.0$ 但无法计算，实际 $\alpha=0$。

### 重新形式化的核心问题
学习映射 $f: \mathcal{X} \times \mathcal{C} \to [0,1]$，满足：
1. **生物学合理性**：$f(x,c) = \sigma(\langle w, \phi(x) \odot g(c) \rangle)$，其中 $g(c) \in [0,1]^d$ 表示基序可及性
2. **细胞系不变性**：$P(\phi(x) \odot g(c) | y, c) = P(\phi(x) \odot g(c) | y)$
3. **连续性**：$g: \mathcal{C} \to [0,1]^d$ Lipschitz连续
4. **稀疏性**：$\|g(c)\|_0 \ll d$（特征选择而非强度调制）

**信息论表述**：最大化 $I(\phi(x) \odot g(c); y)$，最小化 $I(\phi(x) \odot g(c); c | y)$，约束 $I(g(c); c) \geq I_0$（保留细胞系信息于门控中）。

## 解决方案

### 数学描述

#### 1. 可验证对齐架构设计

**架构验证定理**：架构 $A$ 与设计 $D$ 对齐当且仅当存在同构 $\Phi: A \to D$ 使得 $\Phi$ 保持所有约束结构。

**具体实现**：
- **序列编码器**（降维瓶颈）：
  \[
  \phi: \mathcal{X} \to \mathbb{R}^d, \quad z = \phi(x), \quad d = 256
  \]
  使用现有CBAT架构但最终投影到256维，后接LayerNorm。

- **细胞系连续编码器**：
  \[
  \psi: \mathcal{C} \to \mathbb{R}^h, \quad v_c = \psi(c)
  \]
  若无可观测表观特征：$v_c = \text{AttnPool}(\{\phi(x_i): x_i \in S_c\})$，$S_c$ 为 $c$ 的 $k=32$ 个随机样本。

- **信息瓶颈门控生成器**：
  \[
  g: \mathbb{R}^h \to \Delta^{d-1}, \quad g_c = \text{Sparsemax}\left(\frac{W v_c + b}{\tau_c}\right)
  \]
  其中 $\tau_c = \sigma(u^\top v_c) \cdot 9.9 + 0.1 \in [0.1, 10.0]$ 可学习温度，控制稀疏度。

- **调制分类头**：
  \[
  P_\theta(y=1|x,c) = \sigma\left(w^\top (z \odot g_c) + b\right)
  \]

**对齐验证清单**：
1. ✅ 前向传播必经过 $z \odot g_c$
2. ✅ $g_c$ 维度 $d=256$，非标量
3. ✅ 使用 Sparsemax 非 Softmax/线性
4. ✅ 温度可学习、细胞系特异性

#### 2. 渐进式硬约束注入

**三阶段课程学习**：

**阶段1（1 epoch）：特征提取**
- 冻结 $g_c = \mathbf{1}$（全1）
- 训练 $\phi$ 和 $w$ 提取有用特征
- 损失：$\mathcal{L}_{\text{task}} = \mathcal{L}_{\text{IMMAX}}$

**阶段2（2-3 epochs）：门控学习**
- 解冻 $g_c$，初始化稀疏度低（$\tau_c$ 大）
- 引入对齐损失，权重从0线性增至1.0
- 损失：$\mathcal{L} = \mathcal{L}_{\text{task}} + \alpha(t) \mathcal{L}_{\text{align}}$

**阶段3（剩余）：全约束优化**
- 全部约束激活
- 损失：$\mathcal{L} = \mathcal{L}_{\text{task}} + \mathcal{L}_{\text{align}} + \beta \mathcal{L}_{\text{contrast}} + \gamma \mathcal{L}_{\text{entropy}} + \delta \mathcal{L}_{\text{smooth}}$

#### 3. 双重信息瓶颈解耦

**目标**：实现 $I(z \odot g_c; c | y) \to 0$ 同时 $I(g_c; c) \geq I_0$。

**实现**：
- **条件对抗判别器** $D: \mathbb{R}^d \times \{0,1\} \to \mathbb{R}^{|\mathcal{C}|}$
  - 输入：调制特征 $z \odot g_c$ 和标签 $y$
  - 目标：预测细胞系 $c$
  - 使用 Gradient Reversal Layer (GRL) 最大化判别器损失
  - 损失：$\mathcal{L}_{\text{adv}} = \mathbb{E}_{x,c,y}[\log D(z \odot g_c, y)_c]$

- **门控信息保留**：无约束，自然学习 $I(g_c; c)$

**信息论解释**：对抗损失近似最小化 $I(z \odot g_c; c | y)$，而 $g_c$ 自由携带细胞系信息。

#### 4. 硬约束损失函数

**交换对齐损失（改进版）**：
\[
\mathcal{L}_{\text{align}} = \frac{1}{|\mathcal{P}|} \sum_{(i,j) \in \mathcal{P}} \frac{\|z_i \odot g_{c_i} - z_j \odot g_{c_j}\|^2}{\|z_i\| \|z_j\|}
\]
其中 $\mathcal{P} = \{(i,j): y_i = y_j, c_i \neq c_j\}$，标准化缓解尺度问题。

**对比不变性损失**：
\[
\mathcal{L}_{\text{contrast}} = -\frac{1}{B} \sum_{i=1}^B \log \frac{\sum_{j \in \mathcal{P}_i} \exp(\text{sim}(z_i \odot g_{c_i}, z_j \odot g_{c_j})/\tau)}{\sum_{k \in \mathcal{N}_i} \exp(\text{sim}(z_i \odot g_{c_i}, z_k \odot g_{c_k})/\tau)}
\]
$\mathcal{P}_i = \{j: y_j = y_i, c_j \neq c_i\}$，$\mathcal{N}_i = \{k: y_k \neq y_i\}$，$\tau=0.1$。

**熵正则化**：
\[
\mathcal{L}_{\text{entropy}} = \left( H(g_c) - H_{\text{target}} \right)^2, \quad H_{\text{target}} = \log(\sqrt{d}) \approx 2.77
\]
鼓励中等稀疏度（约16个活跃维度）。

**平滑性约束**：
\[
\mathcal{L}_{\text{smooth}} = \frac{1}{|\mathcal{P}_c|} \sum_{(c,c') \in \mathcal{P}_c} \exp\left(-\frac{\|v_c - v_{c'}\|^2}{\sigma^2}\right) \cdot \|g_c - g_{c'}\|_1
\]
其中 $\sigma^2 = \text{median}\{\|v_c - v_{c'}\|^2\}$。

#### 5. 总损失函数
\[
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \alpha \mathcal{L}_{\text{align}} + \beta \mathcal{L}_{\text{contrast}} + \gamma \mathcal{L}_{\text{entropy}} + \delta \mathcal{L}_{\text{smooth}} + \lambda \mathcal{L}_{\text{adv}}
\]
初始权重：$\alpha=1.0, \beta=0.5, \gamma=0.2, \delta=0.1, \lambda=0.2$。

### 核心机制

#### 1. 为什么可验证对齐能避免断层？
**对齐验证协议**：
1. **前向传播追踪**：记录计算图，验证 $z \odot g_c$ 存在
2. **维度检查**：确保 $\dim(g_c) = \dim(z) = 256$
3. **约束可计算性**：预计算 $\mathcal{L}_{\text{align}}$ 在虚拟批次上应非零
4. **生物学合理性**：检查 $g_c$ 稀疏性、非负性

**实现**：在 `__init__` 中添加 `self._verify_architecture()`，训练前运行。

#### 2. 信息瓶颈解耦的数学保证
**定理**（近似）：条件对抗损失 $\mathcal{L}_{\text{adv}}$ 最小化 $I(z \odot g_c; c | y)$ 的上界。

**证明思路**：GAN的f散度最小化等价于互信息最小化，条件版本类似。

**实践优势**：无需估计互信息，直接通过对抗训练实现解耦。

#### 3. 渐进式约束避免模式坍缩
**梯度冲突分析**：$\mathcal{L}_{\text{align}}$ 和 $\mathcal{L}_{\text{contrast}}$ 可能冲突（对齐要求重合，对比要求分离）。

**课程学习缓解**：
- 阶段1：学习基本特征
- 阶段2：逐步引入对齐，特征已初步成形
- 阶段3：全约束，特征稳定

#### 4. 稀疏性的信息论最优性
**目标熵** $H_{\text{target}} = \log(\sqrt{d})$ 对应：
- **最小充分统计量**：$\sqrt{d} \approx 16$ 个特征足以区分互作状态
- **生物学合理性**：典型调控涉及约10-20个TF
- **泛化优势**：有效 VC维 $\approx 16 \ll 256$

### 物理/生物对应

#### 1. 特征调制 → 染色质可及性的数学实现
$z_i$：序列决定的TF结合能（负对数概率）
$g_{c,i}$：核小体占据、组蛋白修饰等决定的**访问概率**
$z_i \cdot g_{c,i}$：**有效结合概率**，乘法模型更符合物理（独立事件联合概率）

#### 2. 信息瓶颈 → 进化保守的调控逻辑
- $z \odot g_c$ 与 $c$ 条件独立：尽管染色质状态不同，活跃互作对暴露**相似的基序组合**
- $g_c$ 携带 $c$ 信息：不同细胞系有不同的可及性模式
- **分离原则**：什么（基序组合）与是否（互作）解耦；哪里（可及性）与是否分离

#### 3. 渐进式约束 → 发育分化轨迹
- 阶段1：识别保守基序
- 阶段2：学习细胞系特异性可及性
- 阶段3：优化组合模式
- 对应分化中染色质逐渐特化的过程

#### 4. 平滑性 → 细胞类型连续统
相似细胞系（如不同组织的上皮细胞）有相似可及性模式，支持在分化轨迹上插值。

## 实施路线图

### 阶段0：架构对齐验证（关键创新）

#### 1. 验证模块实现
```python
class ArchitectureVerifier:
    def __init__(self, model):
        self.model = model

    def verify_feature_modulation(self, batch_size=4):
        """验证特征调制架构"""
        # 创建虚拟输入
        x = torch.randn(batch_size, 768)  # 假定的序列特征
        c = torch.randint(0, 8, (batch_size,))  # 细胞系ID

        # 追踪计算图
        with torch.no_grad():
            # 检查前向传播是否包含 z * g_c
            # 具体实现依赖模型结构
            pass

        return all_checks_passed
```

#### 2. 训练前验证清单
```python
def pre_training_verification():
    checks = []
    checks.append(verify_feature_modulation())
    checks.append(verify_gating_dimension())
    checks.append(verify_constraint_computability())
    checks.append(verify_gradient_flow())

    if not all(checks):
        raise RuntimeError("架构验证失败：方案与实现断层")
```

### 阶段1：核心模块实现

#### 1. 序列编码器（修改现有）
```python
class DimReductionEncoder(nn.Module):
    def __init__(self, original_dim=768, target_dim=256):
        super().__init__()
        self.proj = nn.Linear(original_dim, target_dim)
        self.norm = nn.LayerNorm(target_dim)

    def forward(self, z_orig):
        return self.norm(self.proj(z_orig))
```

#### 2. 信息瓶颈门控生成器
```python
class IBGatingGenerator(nn.Module):
    def __init__(self, input_dim, feature_dim=256):
        super().__init__()
        self.W = nn.Linear(input_dim, feature_dim)
        self.temp_scaler = nn.Linear(input_dim, 1)
        self.temp_shift = 0.1
        self.temp_scale = 9.9

    def forward(self, v_c):
        logits = self.W(v_c)  # [B, d]
        temp = torch.sigmoid(self.temp_scaler(v_c)) * self.temp_scale + self.temp_shift
        return sparsemax(logits / temp), temp.squeeze()
```

#### 3. 条件对抗判别器
```python
class ConditionalDiscriminator(nn.Module):
    def __init__(self, feature_dim, num_classes, num_cells):
        super().__init__()
        self.y_embed = nn.Embedding(num_classes, 16)
        self.net = nn.Sequential(
            nn.Linear(feature_dim + 16, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_cells)
        )

    def forward(self, z_mod, y):
        y_emb = self.y_embed(y)
        return self.net(torch.cat([z_mod, y_emb], dim=1))
```

### 阶段2：训练流程重构

#### 1. 验证集分割
- 从训练集划分20%作为验证集
- 每epoch结束后在验证集评估
- 早停机制：patience=3，基于验证AUPR

#### 2. 三阶段课程学习
```python
def curriculum_schedule(epoch, total_epochs):
    if epoch < 1:
        return {'freeze_gating': True, 'alpha': 0.0, 'beta': 0.0, 'lambda': 0.0}
    elif epoch < 4:
        progress = (epoch - 1) / 3
        return {'freeze_gating': False, 'alpha': progress, 'beta': 0.5*progress, 'lambda': 0.2*progress}
    else:
        return {'freeze_gating': False, 'alpha': 1.0, 'beta': 0.5, 'lambda': 0.2}
```

#### 3. 监控指标扩展
- **核心性能**：训练/验证 AUPR, AUC
- **门控质量**：稀疏度 $\|g_c\|_0/d$，熵 $H(g_c)$，温度 $\tau_c$
- **对齐效果**：$\mathcal{L}_{\text{align}}$，类内跨细胞系距离
- **解耦程度**：对抗损失 $\mathcal{L}_{\text{adv}}$，判别器准确率
- **平滑性**：相似细胞系门控余弦相似度

### 阶段3：推理适配

#### 1. 未知细胞系处理
- **支持集编码**：从测试细胞系采样 $k=64$ 个样本
- **在线适应**：若不收敛，可微调 $g$ 的最后一层（冻结核）

#### 2. 阈值校准
- 在验证集上优化阈值，最大化F1
- 保存最优阈值用于测试

#### 3. 可解释性输出
- **门控热图**：细胞系 × 基序维度
- **重要基序**：$w_i \cdot g_{c,i}$ 排序识别关键TF
- **细胞系相似性**：基于 $g_c$ 的聚类

### 阶段4：失败应对预案

#### 1. 门控坍缩
症状：$g_c$ 全0或全1
应对：增加 $\gamma$，检查温度学习，添加熵下限约束

#### 2. 对齐失败
症状：$\mathcal{L}_{\text{align}}$ 不降
应对：增加批次多样性，增大 $\alpha$，检查梯度冲突

#### 3. 过拟合持续
症状：训练AUPR > 0.95，验证AUPR < 0.70
应对：降低 $d$（256→128），增加Dropout，提前早停

#### 4. 对抗训练不稳定
症状：$\mathcal{L}_{\text{adv}}$ 震荡
应对：降低 $\lambda$，使用梯度裁剪，调整判别器学习率

#### 5. 架构验证失败
症状：验证检查不通过
应对：立即停止，代码审查，修复断层

## 预期行为与理论保障

### 成功标志
1. **泛化差距可控**：训练AUPR ≈ 0.85-0.90，验证AUPR ≥ 0.75，差距 ≤ 0.15
2. **门控质量合理**：稀疏度 10-30%，熵 $H(g_c) \approx 2.77 \pm 0.5$
3. **对齐有效**：$\mathcal{L}_{\text{align}}$ 稳定下降，跨细胞系类内距离 < 类间距离
4. **解耦成功**：判别器准确率接近随机猜测（1/|C|）
5. **平滑性良好**：相似细胞系门控余弦相似度 > 0.8

### 理论优势
1. **零断层保证**：架构验证确保方案与实现对齐
2. **信息论最优**：信息瓶颈平衡压缩与保留
3. **渐进式稳定**：课程学习避免模式坍缩
4. **生物学可信**：特征调制匹配染色质可及性物理

### 创新点总结
1. **架构对齐验证**：首次系统解决方案-实现断层问题
2. **条件对抗解耦**：最小化 $I(z \odot g_c; c | y)$ 的信息论方法
3. **渐进式硬约束**：课程学习缓解梯度冲突
4. **可验证实施**：每个组件都有验证测试

## 风险与缓解

### 高风险项
1. **计算复杂度**：对齐损失 $O(B^2)$，对比损失 $O(B^2)$
   - 缓解：批次大小 $B=32$，采样近似，梯度累积

2. **超参敏感性**：7个损失权重
   - 缓解：渐进式引入，基于验证性能调整

3. **训练不稳定**：对抗训练 + 多重约束
   - 缓解：课程学习，梯度裁剪，单独优化判别器

4. **未知细胞系外推**：支持集编码可能不足
   - 缓解：增大 $k$，在线微调，平滑性约束

### 验证计划
1. **小规模验证**：在5%数据上快速验证核心机制
2. **消融实验**：逐个移除约束，验证必要性
3. **敏感性分析**：扫描关键超参数
4. **生物学验证**：检查门控模式是否对应已知TF

---

**记录点28的本质创新在于：从记录点27的"事后反思"转为"事前预防"，通过架构对齐验证、信息瓶颈解耦、渐进式硬约束三重机制，系统性解决历史断层问题，为突破AUPR 0.75瓶颈提供可验证、可解释、可泛化的数学框架。**