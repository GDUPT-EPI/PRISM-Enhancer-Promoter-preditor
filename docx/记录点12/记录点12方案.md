记录点12修复方案：重新对齐能量耗散与学生竞争，面向 OOD 细胞系的序列泛化

一、目标重申：从“能量耗散 + 学生竞争”回到一个可落地的推理系统

1. 任务本质
- 输入：EP 序列对 (x_E, x_P) 及其所属或潜在细胞系 c。
- 输出：在该细胞系环境下，该 EP 对是否互作的概率 P(y=1 | x_E, x_P, c)。
- 约束：
  - 对训练细胞系，要充分利用 Cell ID 与丰富标签；
  - 对未见细胞系，仅依赖序列与少量观测样本，也能保持排序稳健。

2. 能量模型的不可退让原则
- U_I：仅由序列决定的内在互作势能，跨细胞系共享；
- R_E：环境阻抗，仅由细胞系环境决定（可通过显式标签或支持集隐式推断）；
- 预测公式必须保持：P(y=1) = σ((U_I − R_E) / T)，其中 T 为温度。

3. 学生竞争机制的角色收缩
- Teacher：在训练细胞系上利用 Cell ID + 原型图，提供理想的 R_T。
- Student：在所有细胞系上，仅通过支持集分布，推断 R_S，作为通用环境估计器。
- Student2：保留为拆捷径工具，但不再允许梯度大规模污染 U_I，仅限于约束与 R_E 相关的通道。

记录点12的核心方向是：把所有复杂机制收敛到一条清晰的数据流——先用 U_I 做稳健排序，再用一个真正从分布中学来的 R_E 做温和纠偏，并在训练阶段就严格对齐“按细胞系 episodic 推理”的任务形式。


二、训练与推理任务的统一：从随机 Batch 到显式 Episodic 结构

1. 训练任务重构为 per-cell episodic 形式
- 摒弃“全局混合 Meta‑Batch 上最小化一堆 Loss”的模式，将训练划分为一个个简单的 Task：
  - 每个 Task 对应一个细胞系 c；
  - 对应一个 Support Set S_c 和一个 Query Set Q_c；
  - 对于 S_c 中的 EP 样本，我们允许使用标签（训练细胞系）或仅用非监督信号（OOD 伪任务）来构建环境表征；
  - 对于 Q_c 中的 EP 样本，我们用 (U_I − R_E(c))/T 做预测并计算 IMMAXLoss。

2. Support Set 与 Query Set 的具体划分策略
- 对于训练细胞系：
  - 从该细胞系池中随机采样 N_support 作为 S_c，N_query 作为 Q_c；
  - S_c 与 Q_c 不重叠；
  - S_c 用于 Student 推断 R_S，也可用于 Teacher 构建更稳定的 R_T（如通过原型平均）。
- 对于模拟 OOD 任务：
  - 在训练中保留若干细胞系，不给 Teacher 直接使用 ID；
  - 对这些细胞系，Teacher 也只通过支持集构造某种“软标签” R_ref（例如从预训练模型迁移而来），强迫 Student 在“无 ID 条件下”完成环境推断。

3. 训练循环中的统一流程
- 对于每个 Task（一个细胞系）：
  1. 使用 Backbone 计算所有样本的 U_I（只依赖序列）；
  2. 使用 Student 从 S_c 中的 (U_I, y) 或仅 (U_I) 构造 R_S(c)；
  3. 对训练细胞系，Teacher 使用 Cell ID 或原型图得到 R_T(c)；
  4. 在 Q_c 上计算：
     - 任务损失 L_task = IMMAX(σ((U_I − R_E(c))/T), y)，其中 R_E(c) 可为 R_S(c) 或 Teacher/Student 融合；
     - 蒸馏损失 L_distill = ||R_S(c) − StopGrad(R_T(c))||^2；
     - 竞争损失 L_compete，仅作用于 R_E 相关模块。
  5. 对整个 Task 的损失进行加权求和，反向更新参数。

训练和推理在形式上完全一致：都围绕“给定一个细胞系 + 一个支持集 + 一个查询集”来组织计算。


三、能量系统的简化与分权：保护 U_I，收紧 R_E

1. U_I 的约束方案
- 只保留以下监督信号：
  - 主任务的 IMMAXLoss，在 (U_I − R_E)/T 的输出之上；
  - 适度的正则（如权重衰减），不再引入与 CED‑Net 竞争直接耦合的梯度约束；
  - 对 U_I 的分布做轻量校准（如限制均值与方差在合理范围内），避免过度饱和。
- 显式禁止：
  - CED‑Net 的 Push‑away 直接作用于 U_I；
  - 任何蒸馏损失的梯度穿透 U_I 通道。

2. R_E 的职责重构
- R_E 仅由以下通道生成或融合：
  - `R_T(c)`：Teacher 使用 Cell Embedding + 原型图生成；
  - `R_S(c)`：Student 使用 Support Set 的分布特征生成；
  - 按照简单的可解释规则融合，如：
    - 训练细胞系：R_E(c) = α R_T(c) + (1 − α) R_S(c)，α ∈ [0,1]；
    - 未见细胞系：R_E(c) = R_S(c)。
- 对 R_E 的约束：
  - 稀疏性约束（L1）保留，但权重适度减小，只用于防止 R_E 过度补偿；
  - 与 U_I 正交的线性约束可在表示空间中保留，但不再叠加额外流形损失。

3. Student2 的安全边界
- Student2 继续作为检测投机捷径的对照通道，但：
  - 其输出 R_O 不直接参与预测，只用于计算竞争损失；
  - Push‑away 的梯度严格限定在生成 R_E 的子网络中，不再允许穿透到 U_I 所在 Backbone；
  - APL 只监控 R_E 周边的任务损失，不再以全模型 BCE 作为判断依据。

这样，能量系统最终只保留一条干净的数据流：U_I 由 Backbone 负责长程排序，R_E 由 Teacher/Student 负责环境纠偏，两者在预测公式中以一个简单、稳定的方式结合。


四、学生竞争与蒸馏的收敛：从“多目标同时优化”到“单一物理故事的校正”

1. 蒸馏目标精简
- 对每个细胞系 c，仅保留一个核心蒸馏目标：
  - L_distill(c) = ||R_S(c) − StopGrad(R_T(c))||^2；
- 不再对原型分布的所有中间层施加多重 KL、对齐损失，避免梯度在多个空间来回拉扯。

2. 竞争损失的物理重释：从“全局平均”到“per‑cell episodic”
- Pull‑in：当 Student 在某个细胞系的 episodic Task 上，其主任务损失 L_S_task(c) 明显劣于一个“合理基线”（例如 Teacher 或简单统计模型）时，增加该 Task 上 Student 的学习强度，督促其真正利用该细胞系的 Support Set 学习环境结构；
- Push‑away：当 Opportunist 在某个 Task 上明显优于 Student，但这种优势主要来自“利用训练集特有的投机捷径”而不是稳定的环境特征时，仅在 R_E 相关子网络中对 Opportunist 施加惩罚，并严格截断其梯度不回流到 U_I；
- APL 的更新粒度从“混合 Batch 的全局 EMA”下沉到“per‑cell episodic Task”：
  - 对每个细胞系 c 单独维护 ρ_c = EMA(L_S_task(c)) / EMA(L_O_task(c))，聚焦于该细胞系的任务难度与竞争关系；
  - 根据 ρ_c 在该细胞系相关的更新步骤中动态调节 Student/Opportunist 的相对权重或有效学习率，避免出现“所有细胞系共用一个 ρ，导致 push/pull 长期为 0”的空转状态。

3. 与 U_I 的解耦原则
- 竞争与蒸馏的所有目标仅通过以下参数更新：
  - Teacher/Student/Student2 内部权重；
  - 生成 R_E 的子网络；
  - 与 Cell Prototype Graph 相关的嵌入参数。
- Backbone 中负责 U_I 的部分仅接受来自 L_task 的梯度，并使用明确的梯度截断策略避免来自其他损失的污染。


五、推理流程的落地设计：如何在 predict.py 中真正使用 Student

1. 已知细胞系的推理
- 输入：目标细胞系 c 的全部 EP 样本（或一个较大子集）。
- 流程：
  1. 构造 Support Set S_c（无标签推理时，S_c 仅提供序列；有标签场景下可选用部分标签做更精细校准）；
  2. 使用 Backbone 计算 S_c 上的 U_I，输入 Student，得到 R_S(c)；
  3. 使用 Teacher（基于 Cell ID）得到 R_T(c)；
  4. 按照训练时的融合规则得到 R_E(c)；
  5. 对 Query 集（通常就是 c 的全部 EP 样本）使用 P(y=1)=σ((U_I − R_E(c))/T) 进行预测。

2. 未见细胞系的推理
- 输入：新细胞系 c_new 的全部或部分 EP 样本（一般无标签）。
- 流程：
  1. 从中抽取支持集 S_c_new，使用 Backbone 计算 U_I，并输入 Student 得到 R_S(c_new)；
  2. 不再调用 Teacher 或任何依赖 Cell ID 的通道；
  3. 对剩余 Query 样本，使用 R_E(c_new)=R_S(c_new) 进行预测。

3. 与当前 predict.py 的差异
- 不再在每个 Batch 内单独调用 Student 并根据 AUPR 动态切换 base/student 分支，而是：
  - 先在 Support Set 上一次性估计 R_S；
  - 然后在整个细胞系范围内统一使用 (U_I − R_E)/T；
  - Train 与 inference 的 Task 形式完全一致，无需在推理阶段额外“打补丁”。


六、实现层面的控制原则：避免再次跌入“复杂度陷阱”

1. 每个模块仅承担一个清晰职责
- Backbone：生成 U_I，尽量物理、稳定，不被蒸馏和对抗干扰。
- Teacher：为训练细胞系提供 R_T，长期稳定，不参与所有细胞的即时调节。
- Student：从 Support Set 分布中提取环境特征，生成 R_S。
- Student2：充当 Opportunist，只用来检出不稳健的捷径。

2. 每条损失项都要能在物理故事中解释
- 若某个损失项无法被解释为“帮助 U_I 更真实”或“帮助 R_E 更合理”，就不要加；
- 避免再引入新的流形对齐或额外判别器，先把最小闭环跑通并验证 AUPR/F1。

3. 训练前后指标的检验流程
- 训练中：
  - 监控 per‑cell Task Loss 与 AUPR（在训练集切分出的验证 Task 上）；
  - 确保 Student 在“仅依靠 Support Set”条件下能输出有区分度的 R_S。
- 训练后：
  - 在 domain‑kl/test 上严格按“per‑cell episodic 推理 + 统一 R_E”的流程评估；
  - 对比：
    - 单用 U_I 排序的 AUPR；
    - 使用 R_E 纠偏后的 AUPR；
    - 与第二基线及 cross attn 的差距。


七、预期效果与失败边界

1. 理论上的预期提升
- 在训练细胞系上：
  - U_I 排序能力至少恢复到记录点4的水平甚至略有提升；
  - 通过 R_E 纠偏后，AUPR 应高于仅用 U_I 的结果。
- 在未见细胞系上：
  - 仅依赖 Student 的 R_S，也能维持稳健的排序与合理的 F1，不再出现“Recall≈1, Precision≈0.5”的极端坍塌。

2. 若依然失败的可能原因
- Student 从 Support Set 中仍未真正学到“环境风格”，而只是模仿训练细胞系的平均阻抗；
- U_I 的表达能力不足以支撑跨细胞系排序，此时需要回到 Backbone 结构本身做更深层次的反思（如 CBAT 的结构、锚点策略、RoPE 使用方式等）。

记录点12方案的底线是：先让能量耗散系统与学生竞争机制回到一个简单、可控、与推理完全对齐的闭环中，让模型在训练和预测时“做的是同一件事”。只有在这一基础上，后续才有资格继续引入更复杂的流形对齐或自适应机制，而不是在一个已经错位的目标上继续堆叠复杂度。
