# 记录点34方案：Meta-BAM (Meta-learning based Basis Adaptation Modulation)

## 1. 核心哲学：从“样本平均”转向“机制重构”

### 1.1 问题的本质
在 5 个细胞系上训练，意味着模型能看到的“环境全貌”极其有限。
*   **线性坍塌**：传统的调制（如 FiLM 或简单的点积）在极小样本下会退化为 ID 记忆，因为模型只需要通过“平移”就能在 5 个点上达到最优，这种平移在 OOD 时会由于坐标系失效而彻底崩盘。
*   **平均数陷阱**：16 个样本的均值不仅包含巨大的噪声，更抹杀了调控的“极性”。生物调控不是背景噪音的叠加，而是特定机制的激活。

### 1.2 方案愿景：Meta-BAM
Meta-BAM 的核心思想是：**“全局原子机制 + 局部动态重构”**。模型不学习细胞系本身，而是学习一套通用的“生物逻辑原子”，并根据当前环境的观测证据（支持集/全量分布），动态地重新编排这些原子的组合方式。

---

## 2. 数学形式与架构设计

### 2.1 机制基空间 (Mechanism Basis Space: The "Logic Dictionary")
模型维护一组全局可学习的 **逻辑原子 $\mathbf{V} = \{v_1, v_2, ..., v_K\} \in \mathbb{R}^{K \times D}$**。它们不随细胞系改变，是生物界的“通用调控词典”。

*   **实现原理：潜变量模板 (Latent Templates)**
    每个 $v_k$ 在高维空间中定义了一个“调控原点”。当序列特征 $z_q$ 靠近 $v_k$ 时，意味着该序列在几何上匹配了某种 **生物物理构象** 或 **模体簇 (Motif Cluster)**。
*   **投影机制：从序列到潜质 (Sequence-to-Potential)**
    通过计算 $z_q$ 在各个基向量方向上的投影强度 $p_k = \text{Sim}(\hat{z}_q, \hat{v}_k)$，序列被编码为一个 **“机制潜力向量” $\mathbf{P} \in \mathbb{R}^K$**。
    - $p_k \gg 0$：序列具备响应机制 $k$ 的硬件基础（如有位点）。
    - $p_k \approx 0$：序列对机制 $k$ 免疫。
*   **学习动力学**：
    在训练时，模型被迫通过 5 个环境的差异来“挤压” $\mathbf{V}$。如果某个序列在 A 环境活跃但在 B 环境沉默，模型必须将这种差异归因于环境权重 $\alpha(c)$ 的改变，而将共同的序列特征沉淀到 $\mathbf{V}$ 中。

### 2.2 机制激活与环境编码 (Mechanism Activation: The "Light Switch")
$\alpha_k$ 和 $\alpha_j$ 是通过 **环境编码器 (Environment Encoder)** 作用于机制矩阵 $\mathbf{V}$ 产生的激活权重。

*   **机制矩阵 $\mathbf{V}$**：即 2.1 节定义的全局逻辑原子矩阵 $\mathbf{V} \in \mathbb{R}^{K \times D}$。它是 $\alpha$ 的“靶点”。
*   **生成过程 (How $\alpha$ is born)**：
    1.  **证据收集**：从支持集 $S = \{(z_{s,1}, y_{s,1}), ..., (z_{s,16}, y_{s,16})\}$ 中提取环境证据。
    2.  **响应计算**：计算支持集序列与机制矩阵的交互响应 $R = \text{Sim}(Z_s, \mathbf{V}) \in \mathbb{R}^{16 \times K}$。
    3.  **加权聚合**：利用样本标签 $y_s$ 对响应进行极性加权，提取出在该环境下“真正起作用”的机制证据：
        $$\mathbf{E}_{raw} = \text{Pool}(\text{Linear}(R \oplus Y_s)) \in \mathbb{R}^K$$
    4.  **动量修正与归一化**：
        $$\alpha(c) = \text{EMA}(\mathbf{E}_{raw}, \mathbf{E}_{history}) \xrightarrow{\text{Softmax/Sigmoid}} [0, 1]^K$$
*   **物理意义**：$\alpha$ 是一个长度为 $K$ 的向量。每一个元素 $\alpha_k$ 代表了第 $k$ 号机制在当前细胞系中的 **“开启强度”**。
    - **$\alpha_k \to 1$**：当前环境高度允许机制 $k$ 发生（如相关转录因子高表达，染色质开放）。
    - **$\alpha_k \to 0$**：当前环境屏蔽了机制 $k$。

### 2.3 双线性动态重构方程 (Bilinear Dynamic Reconstruction)
预测不再是简单的线性投影，而是捕捉 **机制协同 (Mechanism Synergy)** 的双线性推演：

$$P(y=1) = \sigma \left( \sum_{k=1}^K \sum_{j=1}^K \alpha_k(c) \alpha_j(c) \cdot \mathbf{W}_{kj} \cdot \phi(z_q, v_k) \phi(z_q, v_j) + \text{Bias} \right)$$

#### **变量明确定义：**
| 符号 | 定义 | 物理/数学含义 |
| :--- | :--- | :--- |
| $P(y=1)$ | **预测概率** | E-P 对在特定环境下的互作概率。 |
| $\sigma$ | **Sigmoid 函数** | 将能量分数映射至 $[0, 1]$ 区间。 |
| $z_q$ | **Query 特征向量** | 由 CBAT Backbone 提取的序列内蕴特征 ($\in \mathbb{R}^D$)。 |
| $v_k, v_j$ | **机制基向量** | 全局共享的逻辑原子 ($\in \mathbb{R}^D$)，代表原子化的调控模板。 |
| $\phi(z, v)$ | **余弦相似度** | $\frac{z^T v}{\|z\| \|v\|}$，衡量序列对该机制的 **匹配潜力**。超球面投影封杀了平移作弊。 |
| $\alpha_k(c)$ | **环境激活权重** | 环境 $c$ 对机制 $k$ 的实时允许程度 ($\in [0, 1]$)，由支持集和动量指纹共同决定。 |
| $\mathbf{W}_{kj}$ | **机制交互系数** | 全局学习的对称矩阵，定义了机制 $k$ 与 $j$ 之间的 **协同($>0$)或拮抗($<0$)** 关系。 |
| $K$ | **机制总数** | 预定义的基向量数量（如 64 或 128），决定了逻辑空间的维度。 |
| $\text{Bias}$ | **全局偏置** | 修正基础互作概率的偏移。 |

*   **公式逻辑**：该方程描述了——如果环境 $c$ 允许机制 $k$ 和 $j$ 同时发生（$\alpha_k \alpha_j$），且序列 $z_q$ 同时具备响应这两者的潜力（$\phi_k \phi_j$），则根据它们之间的耦合关系 $\mathbf{W}_{kj}$ 贡献最终的互作能量。这正是实现“序列 A 在环境 B 表现不同”的数学推演基础。

### 2.4 架构选型讨论：为何选择双线性而非 Attention/Mamba？
针对机制调制层，不同架构的效果对比：

| 架构 | 好处 | 坏处 |
| :--- | :--- | :--- |
| **双线性 (Bilinear)** | **极强的逻辑可解释性**。明确捕捉机制 $i$ 与 $j$ 的二阶交互（协同/拮抗），符合生物调控的逻辑门特性。 | 机制数 $K$ 较大时，$\mathbf{W}$ 参数量呈平方增长。 |
| **Attention** | **全局建模能力强**。适合长序列依赖。 | 容易陷入“平均数陷阱”。在高稀疏环境下，容易让所有机制贡献趋同，模糊了特定机制的极性激活。 |
| **Mamba / RWKV** | **线性推理效率极高**。在处理超长序列时优势明显。 | **不适合机制集建模**。Mamba 依赖序列顺序（Causal），而生物机制基空间是 **无序集合 (Set)**。强制排序会引入不必要的偏见。 |
| **条件门控 (Conditional Gating)** | **直接且高效**。适合处理“If-Then”逻辑。 | 缺乏机制间的二阶交互建模，难以理解复杂的协同调控。 |

**最终决策**：采用 **双线性重构 + 机制池化**。因为我们的核心需求是 **“在极少环境下进行逻辑推演”**，双线性提供的二阶交互是实现“功能反转”理解的关键数学基础。

### 3.1 跨序列逻辑推理 (In-Context Reasoning)
模型在 5 个训练集上学到的不是“特征 A 对应标签 1”，而是：
**“如果在当前支持集中，展现了机制 $v_k$ 的富集，那么具有特征 $z_q$ 的序列应当被增强/抑制。”**
这套“如果-那么”的推理逻辑是跨细胞系通用的。面对数千个 OOD 细胞系，模型通过观察其支持集，识别出其独特的 $\alpha(c)$（机制组合谱），从而实现逻辑层面的外推。

### 3.2 机制压缩与解耦约束 (Information Bottleneck & Decoupling)
单纯的 GRL 容易导致特征坍塌（置零或变脏）。为了确保 $\alpha$ 具有真正的物理含义，必须引入 **“正向存在性约束”**：

1.  **机制独立性损失 (Orthogonal Loss)**：
    $$\mathcal{L}_{orth} = \|\mathbf{V}\mathbf{V}^T - \mathbf{I}\|_F^2$$
    确保机制基向量在几何上正交，减少逻辑冗余。
2.  **交换不变性损失 (Swap Invariance Loss)**：
    从同一细胞系中抽取两组不同的支持集 $S_1, S_2$，强制 $\alpha(S_1) \approx \alpha(S_2)$。
    这确保了 $\alpha$ 捕捉的是 **细胞系的稳定物理特质**，而非个别样本的随机噪声。
3.  **支持集重构 (Support Set Reconstruction: The "Anti-Dirty" Head)**：
    引入一个轻量级解码器 $f_{dec}(\alpha, z_s)$，其架构为一个简单的两层 MLP。
    - **输入**：当前环境的机制权重 $\alpha(c)$ 和支持集中某样本的序列特征 $z_s$。
    - **目标**：重构该样本在支持集中的原始标签 $y_s$。
    - **逻辑基础**：如果 $\alpha$ 为了逃避 GRL 而选择“变脏”（变成随机噪声或常数），那么 $f_{dec}$ 将无法利用 $\alpha$ 来解释支持集内部的已知实验结果。
    - **强制信息流**：这迫使 $\alpha$ 必须包含解释该细胞系调控逻辑的 **充分必要信息**，即它必须是一个有效的“环境描述符”。
4.  **对抗清洗 (Adversarial GRL)**：
    在满足上述“有意义”约束的前提下，再通过 GRL 剥离细胞 ID 信息。此时的 $\alpha$ 既不能直接告诉判别器 ID，又必须具备解释该环境调控逻辑的能力。

---

## 4. 算法流程 (OOD 推理时)

1.  **指纹采样 (Profiling Phase)**：
    *   读取新细胞系 $c_{new}$ 的 16 个样本（或更多）。
    *   通过环境编码器，将这组样本映射到机制基空间 $\mathbf{V}$，计算其响应谱 $\alpha(c_{new})$。
2.  **逻辑对齐 (Alignment Phase)**：
    *   CBAT 提取 Query 序列特征 $z_q$。
    *   计算 $z_q$ 与 $K$ 个机制原子的匹配度。
3.  **预测 (Prediction Phase)**：
    *   根据 $\alpha(c_{new})$ 对匹配度进行加权求和，输出最终能量。

---

## 5. 验证与质检 (Verification & QA)

为了确保模型真正掌握了推理逻辑而非记忆，设计以下质检实验：

1.  **机制消融 (Mechanism Ablation)**：
    *   在推理时人为置零某个 $\alpha_k(c)$，观察预测结果的变化。如果模型掌握了逻辑，特定的机制消融应对应特定的生物学功能丧失。
2.  **指纹漂移测试 (Fingerprint Drift)**：
    *   将 A 细胞系的指纹 $\mathbf{E}_A$ 强行作用于 B 细胞系的序列 $z_B$。模型应输出 A 环境下的逻辑结果。这验证了环境与序列的 **完全解耦**。
3.  **正交性监控**：
    *   实时监控 $\mathbf{V}$ 的奇异值分布。如果出现坍塌，说明机制原子不再独立。
4.  **OOD 稳定性**：
    *   在完全未见的 OOD 细胞系上，观察 $\alpha(c)$ 的收敛速度。优秀的 Meta-BAM 应当在 16 个样本内迅速锁定环境状态。

---

## 6. 结论

记录点 34 (Meta-BAM) 方案通过 **“原子化机制”** 解决了 5 个训练集样本稀疏的问题，通过 **“动量指纹直方图”** 解决了 16 个样本噪声大的问题，通过 **“超球面投影”** 封杀了减法作弊，最终实现了从“记忆”到“推理”的范式转移。

这不再是一个简单的分类模型，而是一个能根据观测证据，实时重组调控逻辑的 **生物物理推演引擎**。
